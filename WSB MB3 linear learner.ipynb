{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-1-011113936377\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "session = sagemaker.Session()\n",
    "bucket = session.default_bucket()\n",
    "\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 sync s3://{bucket}/wsb/data/ data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import pytz\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "token_pattern = re.compile(r\"(?u)\\b\\w\\w+\\b\")\n",
    "\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc.lower()) if len(t) >= 2 and re.match(\"[a-z].*\",t) \n",
    "                and re.match(token_pattern, t) and t.upper() not in allsymbols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ET = pytz.timezone('US/Eastern')\n",
    "\n",
    "ignorelist=[\"DD\",\"FREE\",\"CASH\",\"ON\",\"I\"]\n",
    "allsymbols=[]\n",
    "with open(\"allsymbols.txt\") as fh:\n",
    "  allsymbols=fh.readlines()\n",
    "allsymbols = [x.strip() for x in allsymbols]\n",
    "\n",
    "dt=datetime.timedelta(days=7)\n",
    "\n",
    "wnl = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, sys\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def update_progress(progress):\n",
    "    bar_length = 20\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "\n",
    "    block = int(round(bar_length * progress))\n",
    "\n",
    "    clear_output(wait = True)\n",
    "    text = \"Progress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "stockdata={}\n",
    "def getstockprice(symbol,date):\n",
    "    if symbol not in stockdata:\n",
    "        with open(\"stockprices/\"+symbol,\"r\") as fh:\n",
    "            data=json.load(fh)\n",
    "        stockdata[symbol]={}\n",
    "        for stockday in data:\n",
    "            indate=datetime.datetime.strptime(stockday[\"begins_at\"],\"%Y-%m-%dT%H:%M:%SZ\").date()\n",
    "            stockdata[symbol][indate]=stockday\n",
    "    today=datetime.date.today()\n",
    "    while True:\n",
    "        #print(date)\n",
    "        if date in stockdata[symbol]:\n",
    "            return float(stockdata[symbol][date]['close_price'])\n",
    "        date=date+datetime.timedelta(days=1)\n",
    "        if date>today:\n",
    "            break\n",
    "    raise Exception(\"No stock data found\")\n",
    "    return None\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [####################] 99.9%\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(\"data/\")\n",
    "\n",
    "foundsymbols=[]\n",
    "relevant_posts = []\n",
    "i=0\n",
    "for file in files:\n",
    "  if(round(i/100,0)==i/100):\n",
    "        update_progress(i / len(files))  \n",
    "  with open(\"data/\"+file,\"r\") as fh:\n",
    "    try:\n",
    "        data=json.load(fh)\n",
    "        text = (data[\"title\"]+\" \"+data[\"selftext\"]).replace('\\\"','').replace('\\'','')\n",
    "        allmatches=[]\n",
    "        matches=re.findall('\\W*([A-Z][A-Z\\.]{0,3})\\W',text)\n",
    "        for submatch in matches:\n",
    "            allmatches.append({submatch:submatch})\n",
    "            #pass\n",
    "        matches2=re.findall('\\W*(\\$[a-z\\.]{1,4})',text)\n",
    "        for submatch in matches2:\n",
    "            allmatches.append({submatch.upper()[1:]:submatch})\n",
    "        thesesymbols=[]\n",
    "        #print(allmatches)\n",
    "        for submatch in allmatches:\n",
    "            symbol=list(submatch.keys())[0]\n",
    "            #print(submatch.keys())\n",
    "            #print(symbol)\n",
    "            #print([list(x.keys())[0] for x in thesesymbols])\n",
    "            if symbol in allsymbols and symbol not in [list(x.keys())[0] for x in thesesymbols] and symbol not in ignorelist:\n",
    "                thesesymbols.append(submatch)\n",
    "                if symbol not in foundsymbols:\n",
    "                    foundsymbols.append(symbol)\n",
    "        if len(thesesymbols)>0:\n",
    "            relevant_posts.append({\"data\":data,\"symbols\":thesesymbols})\n",
    "            #print(thesesymbols)\n",
    "    except Exception as err:\n",
    "      print(\"Error with\",file)\n",
    "      raise(err)\n",
    "  i+=1\n",
    "    \n",
    "\n",
    "  #if i>1000:\n",
    "  #  break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3661\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['TSLA',\n",
       " 'B',\n",
       " 'AMZN',\n",
       " 'COST',\n",
       " 'C',\n",
       " 'LULU',\n",
       " 'AMD',\n",
       " 'FB',\n",
       " 'PTON',\n",
       " 'AAPL',\n",
       " 'GOLD',\n",
       " 'ROKU',\n",
       " 'NFLX',\n",
       " 'DIS',\n",
       " 'HAS',\n",
       " 'GOOD',\n",
       " 'ONCY',\n",
       " 'SPCE',\n",
       " 'AMC',\n",
       " 'KR',\n",
       " 'PM',\n",
       " 'ABC',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'CYBR',\n",
       " 'PANW',\n",
       " 'RPD',\n",
       " 'EDIT',\n",
       " 'DTE',\n",
       " 'DCOM',\n",
       " 'AT',\n",
       " 'ACB',\n",
       " 'THC',\n",
       " 'MU',\n",
       " 'IP',\n",
       " 'AG',\n",
       " 'GILD',\n",
       " 'TJX',\n",
       " 'HTZ',\n",
       " 'TVTY',\n",
       " 'DGX',\n",
       " 'QQQ',\n",
       " 'TA',\n",
       " 'BYND',\n",
       " 'POST',\n",
       " 'SR',\n",
       " 'NIO',\n",
       " 'RING',\n",
       " 'A',\n",
       " 'NEW',\n",
       " 'IT',\n",
       " 'FOSL',\n",
       " 'BK',\n",
       " 'PINS',\n",
       " 'KRTX',\n",
       " 'OVID',\n",
       " 'DOW',\n",
       " 'SBUX',\n",
       " 'VC',\n",
       " 'MCD',\n",
       " 'MSFT',\n",
       " 'WMT',\n",
       " 'SNAP',\n",
       " 'PECK',\n",
       " 'HUGE',\n",
       " 'GDP',\n",
       " 'WELL',\n",
       " 'CDC',\n",
       " 'BA',\n",
       " 'V',\n",
       " 'FAT',\n",
       " 'NOC',\n",
       " 'LMT',\n",
       " 'RH',\n",
       " 'AAL',\n",
       " 'GO',\n",
       " 'SDC',\n",
       " 'ALGN',\n",
       " 'ONE',\n",
       " 'ATVI',\n",
       " 'M',\n",
       " 'CEO',\n",
       " 'K',\n",
       " 'ALLY',\n",
       " 'SIX',\n",
       " 'CME',\n",
       " 'AM',\n",
       " 'LIVE',\n",
       " 'FIT',\n",
       " 'SWBI',\n",
       " 'EC',\n",
       " 'F',\n",
       " 'CRM',\n",
       " 'BAC',\n",
       " 'CTO',\n",
       " 'PEP',\n",
       " 'UAL',\n",
       " 'DAL',\n",
       " 'JNJ',\n",
       " 'PCG',\n",
       " 'E',\n",
       " 'PLUS',\n",
       " 'AMTD',\n",
       " 'TTD',\n",
       " 'DEA',\n",
       " 'CBD',\n",
       " 'CCL',\n",
       " 'ARE',\n",
       " 'OUT',\n",
       " 'G',\n",
       " 'BMO',\n",
       " 'IONS',\n",
       " 'FOR',\n",
       " 'HAL',\n",
       " 'INFY',\n",
       " 'KO',\n",
       " 'SYF',\n",
       " 'NDAQ',\n",
       " 'NEE',\n",
       " 'ERIC',\n",
       " 'DPZ',\n",
       " 'LUV',\n",
       " 'UNP',\n",
       " 'AXP',\n",
       " 'SNY',\n",
       " 'NEXT',\n",
       " 'MMM',\n",
       " 'UPS',\n",
       " 'CAT',\n",
       " 'TRU',\n",
       " 'HOG',\n",
       " 'APPS',\n",
       " 'ELLO',\n",
       " 'LOAN',\n",
       " 'VZ',\n",
       " 'APHA',\n",
       " 'R',\n",
       " 'SO',\n",
       " 'MGM',\n",
       " 'T',\n",
       " 'ROCK',\n",
       " 'SSSS',\n",
       " 'LAND',\n",
       " 'AI',\n",
       " 'III',\n",
       " 'PLUG',\n",
       " 'EOD',\n",
       " 'ULTA',\n",
       " 'GM',\n",
       " 'BBBY',\n",
       " 'CPRX',\n",
       " 'TD',\n",
       " 'CLX',\n",
       " 'TH',\n",
       " 'ARCH',\n",
       " 'BE',\n",
       " 'KHC',\n",
       " 'PG',\n",
       " 'SHOP',\n",
       " 'TQQQ',\n",
       " 'ETSY',\n",
       " 'TSM',\n",
       " 'BSX',\n",
       " 'PE',\n",
       " 'GF',\n",
       " 'FCEL',\n",
       " 'NVDA',\n",
       " 'GPS',\n",
       " 'FT',\n",
       " 'GME',\n",
       " 'BIG',\n",
       " 'HPQ',\n",
       " 'HP',\n",
       " 'UBER',\n",
       " 'BY',\n",
       " 'ANY',\n",
       " 'ALKS',\n",
       " 'ALL',\n",
       " 'NOW',\n",
       " 'STAY',\n",
       " 'CFA',\n",
       " 'BABA',\n",
       " 'ACAD',\n",
       " 'KSS',\n",
       " 'CROX',\n",
       " 'IBM',\n",
       " 'IR',\n",
       " 'JP',\n",
       " 'DFS',\n",
       " 'LL',\n",
       " 'DB',\n",
       " 'SQ',\n",
       " 'MTCH',\n",
       " 'ATH',\n",
       " 'USA',\n",
       " 'OR',\n",
       " 'SELF',\n",
       " 'INO',\n",
       " 'TWO',\n",
       " 'UI',\n",
       " 'NMI',\n",
       " 'NMIH',\n",
       " 'WTI',\n",
       " 'CL',\n",
       " 'IOVA',\n",
       " 'LN',\n",
       " 'L',\n",
       " 'PD',\n",
       " 'CAR',\n",
       " 'SMFG',\n",
       " 'ZM',\n",
       " 'JPM',\n",
       " 'CFO',\n",
       " 'EVER',\n",
       " 'KL',\n",
       " 'WPM',\n",
       " 'SSRM',\n",
       " 'GEO',\n",
       " 'XLNX',\n",
       " 'EAST',\n",
       " 'CSCO',\n",
       " 'PSA',\n",
       " 'TWTR',\n",
       " 'ENPH',\n",
       " 'ALLT',\n",
       " 'GAIN',\n",
       " 'O',\n",
       " 'D',\n",
       " 'H',\n",
       " 'ZNGA',\n",
       " 'AUPH',\n",
       " 'PCIM',\n",
       " 'PS',\n",
       " 'GNUS',\n",
       " 'DBX',\n",
       " 'HSBC',\n",
       " 'UNIT',\n",
       " 'AIMT',\n",
       " 'BBY',\n",
       " 'LYFT',\n",
       " 'GOOG',\n",
       " 'OXY',\n",
       " 'IMO',\n",
       " 'DHT',\n",
       " 'TNK',\n",
       " 'FRO',\n",
       " 'NAT',\n",
       " 'SA',\n",
       " 'TV',\n",
       " 'DVD',\n",
       " 'RGR',\n",
       " 'RAD',\n",
       " 'J',\n",
       " 'AYI',\n",
       " 'KB',\n",
       " 'KBH',\n",
       " 'WD',\n",
       " 'WDFC',\n",
       " 'ADES',\n",
       " 'XP',\n",
       " 'AGTC',\n",
       " 'AMAG',\n",
       " 'SMPL',\n",
       " 'LB',\n",
       " 'AZZ',\n",
       " 'XRX',\n",
       " 'VOYA',\n",
       " 'BLK',\n",
       " 'PDT',\n",
       " 'BAM',\n",
       " 'KTOS',\n",
       " 'IQ',\n",
       " 'TEVA',\n",
       " 'MO',\n",
       " 'BUD',\n",
       " 'PRT',\n",
       " 'ES',\n",
       " 'WORK',\n",
       " 'CMG',\n",
       " 'PPT',\n",
       " 'BRO',\n",
       " 'APA',\n",
       " 'DXC',\n",
       " 'DISH',\n",
       " 'SNR',\n",
       " 'FIVE',\n",
       " 'NI',\n",
       " 'KMI',\n",
       " 'OSG',\n",
       " 'STNG',\n",
       " 'EURN',\n",
       " 'OSTK',\n",
       " 'EA',\n",
       " 'TS',\n",
       " 'YY',\n",
       " 'MAR',\n",
       " 'PAR',\n",
       " 'ET',\n",
       " 'TLRY',\n",
       " 'SQQQ',\n",
       " 'ESNT',\n",
       " 'PLC',\n",
       " 'UBS',\n",
       " 'ALLK',\n",
       " 'LOGI',\n",
       " 'BIDU',\n",
       " 'ANET',\n",
       " 'CRWD',\n",
       " 'CAN',\n",
       " 'PZZA',\n",
       " 'WEN',\n",
       " 'HEAR',\n",
       " 'JACK',\n",
       " 'Z',\n",
       " 'ZS',\n",
       " 'ABIO',\n",
       " 'TGT',\n",
       " 'DKNG',\n",
       " 'MS',\n",
       " 'REAL',\n",
       " 'WOW',\n",
       " 'CGC',\n",
       " 'FSLY',\n",
       " 'CTL',\n",
       " 'ICD',\n",
       " 'PNC',\n",
       " 'APRN',\n",
       " 'TDA',\n",
       " 'SHAK',\n",
       " 'HD',\n",
       " 'WKHS',\n",
       " 'VCEL',\n",
       " 'MDWD',\n",
       " 'VFF',\n",
       " 'DOCU',\n",
       " 'EB',\n",
       " 'TCOM',\n",
       " 'XOM',\n",
       " 'AAOI',\n",
       " 'RCL',\n",
       " 'PLNT',\n",
       " 'MSB',\n",
       " 'W',\n",
       " 'PHAT',\n",
       " 'GE',\n",
       " 'STZ',\n",
       " 'FDX',\n",
       " 'EV',\n",
       " 'GL',\n",
       " 'FL',\n",
       " 'SRPT',\n",
       " 'SLDB',\n",
       " 'STMP',\n",
       " 'NTNX',\n",
       " 'SRNE',\n",
       " 'PHD',\n",
       " 'SCI',\n",
       " 'TTWO',\n",
       " 'NHC',\n",
       " 'SE',\n",
       " 'RNG',\n",
       " 'LOCO',\n",
       " 'DLTR',\n",
       " 'AIG',\n",
       " 'TAL',\n",
       " 'DE',\n",
       " 'DXCM',\n",
       " 'APT',\n",
       " 'NKLA',\n",
       " 'FCF',\n",
       " 'HOME',\n",
       " 'TELL',\n",
       " 'TLT',\n",
       " 'MIND',\n",
       " 'CNA',\n",
       " 'WINS',\n",
       " 'TREE',\n",
       " 'MTD',\n",
       " 'KRP',\n",
       " 'WFC',\n",
       " 'GS',\n",
       " 'UNH',\n",
       " 'INTC',\n",
       " 'BIIB',\n",
       " 'HCA',\n",
       " 'BOH',\n",
       " 'MTB',\n",
       " 'ONB',\n",
       " 'SAP',\n",
       " 'BMRC',\n",
       " 'CMA',\n",
       " 'PHG',\n",
       " 'CBU',\n",
       " 'KMB',\n",
       " 'TFC',\n",
       " 'PLD',\n",
       " 'LII',\n",
       " 'LLY',\n",
       " 'SNA',\n",
       " 'LVS',\n",
       " 'TRV',\n",
       " 'LRCX',\n",
       " 'KALU',\n",
       " 'EMR',\n",
       " 'CIT',\n",
       " 'FITB',\n",
       " 'BG',\n",
       " 'VIR',\n",
       " 'MRNA',\n",
       " 'CODX',\n",
       " 'APEX',\n",
       " 'BB',\n",
       " 'CARV',\n",
       " 'MOMO',\n",
       " 'NVO',\n",
       " 'LNG',\n",
       " 'USAC',\n",
       " 'DAX',\n",
       " 'EARS',\n",
       " 'CZR',\n",
       " 'AN',\n",
       " 'EYE',\n",
       " 'MA',\n",
       " 'ATR',\n",
       " 'GT',\n",
       " 'MRK',\n",
       " 'PT',\n",
       " 'KN',\n",
       " 'JCO',\n",
       " 'UTI',\n",
       " 'CVM',\n",
       " 'AZN',\n",
       " 'GD',\n",
       " 'SGA',\n",
       " 'TTNP',\n",
       " 'FLAT',\n",
       " 'NG',\n",
       " 'MTNB',\n",
       " 'ALGT',\n",
       " 'IRL',\n",
       " 'ARDS',\n",
       " 'WASH',\n",
       " 'WH',\n",
       " 'CO',\n",
       " 'FOX',\n",
       " 'LE',\n",
       " 'VEEV',\n",
       " 'SAFE',\n",
       " 'ISRG',\n",
       " 'TDOC',\n",
       " 'ST',\n",
       " 'WIX',\n",
       " 'FCX',\n",
       " 'CUZ',\n",
       " 'ASRT',\n",
       " 'VAC',\n",
       " 'TMUS',\n",
       " 'VSTO',\n",
       " 'SPR',\n",
       " 'RMED',\n",
       " 'OLN',\n",
       " 'UXIN',\n",
       " 'KEYS',\n",
       " 'MASI',\n",
       " 'RTX',\n",
       " 'CHGG',\n",
       " 'SP',\n",
       " 'IRS',\n",
       " 'CSX',\n",
       " 'BBW',\n",
       " 'ING',\n",
       " 'RVLV',\n",
       " 'CAC',\n",
       " 'MAN',\n",
       " 'BR',\n",
       " 'THO',\n",
       " 'AVGO',\n",
       " 'HRB',\n",
       " 'PLAY',\n",
       " 'HDS',\n",
       " 'LOVE',\n",
       " 'CHS',\n",
       " 'TLRD',\n",
       " 'SECO',\n",
       " 'DLTH',\n",
       " 'SHLO',\n",
       " 'ASNA',\n",
       " 'CPST',\n",
       " 'JW.A',\n",
       " 'AZRE',\n",
       " 'ADXS',\n",
       " 'CASY',\n",
       " 'LMNR',\n",
       " 'BBCP',\n",
       " 'NEPT',\n",
       " 'OXM',\n",
       " 'SPCB',\n",
       " 'TMDX',\n",
       " 'TUFN',\n",
       " 'LIVX',\n",
       " 'RENN',\n",
       " 'SMMT',\n",
       " 'CRWS',\n",
       " 'UROV',\n",
       " 'CHWY',\n",
       " 'CAKE',\n",
       " 'API',\n",
       " 'FSD',\n",
       " 'ACA',\n",
       " 'CI',\n",
       " 'ANTM',\n",
       " 'HUM',\n",
       " 'MOH',\n",
       " 'CNC',\n",
       " 'NCLH',\n",
       " 'TWNK',\n",
       " 'CARS',\n",
       " 'BBVA',\n",
       " 'JWN',\n",
       " 'HBI',\n",
       " 'FOXA',\n",
       " 'AEO',\n",
       " 'SKX',\n",
       " 'URBN',\n",
       " 'PAGS',\n",
       " 'NAVI',\n",
       " 'CMD',\n",
       " 'PENN',\n",
       " 'VERY',\n",
       " 'TVIX',\n",
       " 'ZIV',\n",
       " 'CBOE',\n",
       " 'PUMP',\n",
       " 'MOD',\n",
       " 'PBPB',\n",
       " 'PCB',\n",
       " 'ITCI',\n",
       " 'PSX',\n",
       " 'MFA',\n",
       " 'TAP',\n",
       " 'DEO',\n",
       " 'SEAS',\n",
       " 'TX',\n",
       " 'AVTR',\n",
       " 'JMIA',\n",
       " 'TLSA',\n",
       " 'HE',\n",
       " 'GRPN',\n",
       " 'SINO',\n",
       " 'HSY',\n",
       " 'XRAY',\n",
       " 'MRVL',\n",
       " 'RYTM',\n",
       " 'GPRO',\n",
       " 'ASX',\n",
       " 'EFT',\n",
       " 'CLB',\n",
       " 'ICE',\n",
       " 'NC',\n",
       " 'HA',\n",
       " 'HLT',\n",
       " 'IMAX',\n",
       " 'AR',\n",
       " 'KMX',\n",
       " 'AZO',\n",
       " 'IBEX',\n",
       " 'BGCP',\n",
       " 'INFO',\n",
       " 'MANU',\n",
       " 'UN',\n",
       " 'FDP',\n",
       " 'FLR',\n",
       " 'TOT',\n",
       " 'IBP',\n",
       " 'RILY',\n",
       " 'UNVR',\n",
       " 'PDD',\n",
       " 'VER',\n",
       " 'PLMR',\n",
       " 'SASR',\n",
       " 'OPRT',\n",
       " 'ZEAL',\n",
       " 'MRTX',\n",
       " 'RL',\n",
       " 'SCCO',\n",
       " 'WYNN',\n",
       " 'AIMC',\n",
       " 'BX',\n",
       " 'CLVS',\n",
       " 'CCO',\n",
       " 'CORT',\n",
       " 'ETM',\n",
       " 'GPN',\n",
       " 'GTN',\n",
       " 'IPG',\n",
       " 'KRYS',\n",
       " 'NBSE',\n",
       " 'NXST',\n",
       " 'OMC',\n",
       " 'SSP',\n",
       " 'SBBP',\n",
       " 'SBGI',\n",
       " 'TGNA',\n",
       " 'TXG',\n",
       " 'JBL',\n",
       " 'NEOG',\n",
       " 'CMTL',\n",
       " 'CTAS',\n",
       " 'NKE',\n",
       " 'SNX',\n",
       " 'DAVA',\n",
       " 'WOR',\n",
       " 'AIR',\n",
       " 'FUL',\n",
       " 'ACN',\n",
       " 'CAG',\n",
       " 'GDS',\n",
       " 'CAMP',\n",
       " 'MTN',\n",
       " 'PRGS',\n",
       " 'UEPS',\n",
       " 'ATOM',\n",
       " 'TC',\n",
       " 'CPA',\n",
       " 'CTV',\n",
       " 'QCOM',\n",
       " 'FVRR',\n",
       " 'FLIR',\n",
       " 'RELL',\n",
       " 'PLOW',\n",
       " 'OKE',\n",
       " 'ALLO',\n",
       " 'CMO',\n",
       " 'CR',\n",
       " 'PSC',\n",
       " 'COO',\n",
       " 'IDE',\n",
       " 'RE',\n",
       " 'FLY',\n",
       " 'BW',\n",
       " 'EH',\n",
       " 'NOK',\n",
       " 'ALB',\n",
       " 'ATNM',\n",
       " 'OPK',\n",
       " 'NAK',\n",
       " 'KT',\n",
       " 'PBR',\n",
       " 'ONVO',\n",
       " 'OI',\n",
       " 'RST',\n",
       " 'UL',\n",
       " 'CBNK',\n",
       " 'GRUB',\n",
       " 'PEG',\n",
       " 'ROK',\n",
       " 'TEAM',\n",
       " 'AC',\n",
       " 'VALE',\n",
       " 'BHP',\n",
       " 'SRG',\n",
       " 'VNO',\n",
       " 'CLDR',\n",
       " 'NET',\n",
       " 'AFYA',\n",
       " 'TY',\n",
       " 'AMG',\n",
       " 'CRMD',\n",
       " 'GGAL',\n",
       " 'BMA',\n",
       " 'SUPV',\n",
       " 'BBAR',\n",
       " 'BCH',\n",
       " 'SIRI',\n",
       " 'APRE',\n",
       " 'AUY',\n",
       " 'SWN',\n",
       " 'OKTA',\n",
       " 'DK',\n",
       " 'DVAX',\n",
       " 'NCR',\n",
       " 'FLEX',\n",
       " 'AVD',\n",
       " 'ECL',\n",
       " 'SD',\n",
       " 'TSN',\n",
       " 'COMM',\n",
       " 'FTC',\n",
       " 'RBC',\n",
       " 'CM',\n",
       " 'IEX',\n",
       " 'GENE',\n",
       " 'RAND',\n",
       " 'PRO',\n",
       " 'HPE',\n",
       " 'CARE',\n",
       " 'IVR',\n",
       " 'TDW',\n",
       " 'TYG',\n",
       " 'EAT',\n",
       " 'SAGE',\n",
       " 'RETA',\n",
       " 'BMRN',\n",
       " 'ALXN',\n",
       " 'REGN',\n",
       " 'RGNX',\n",
       " 'RARE',\n",
       " 'GSK',\n",
       " 'BMY',\n",
       " 'ABBV',\n",
       " 'AMGN',\n",
       " 'SGEN',\n",
       " 'FORD',\n",
       " 'LONE',\n",
       " 'SMH',\n",
       " 'FANG',\n",
       " 'BBC',\n",
       " 'ARCT',\n",
       " 'BNTX',\n",
       " 'HTBX',\n",
       " 'VXRT',\n",
       " 'BCS',\n",
       " 'INCY',\n",
       " 'MLM',\n",
       " 'MIC',\n",
       " 'MYGN',\n",
       " 'TRUP',\n",
       " 'PFD',\n",
       " 'TAK',\n",
       " 'MYL',\n",
       " 'TIF',\n",
       " 'HIBB',\n",
       " 'ORCL',\n",
       " 'CAH',\n",
       " 'NYT',\n",
       " 'DG',\n",
       " 'LEG',\n",
       " 'RUN',\n",
       " 'NATH',\n",
       " 'KIDS',\n",
       " 'TOPS',\n",
       " 'ABT',\n",
       " 'PRPL',\n",
       " 'CC',\n",
       " 'AMED',\n",
       " 'BKNG',\n",
       " 'SEE',\n",
       " 'HON',\n",
       " 'NR',\n",
       " 'CFR',\n",
       " 'WWE',\n",
       " 'ADI',\n",
       " 'PEY',\n",
       " 'ESPR',\n",
       " 'JAN',\n",
       " 'ETFC',\n",
       " 'HONE',\n",
       " 'EARN',\n",
       " 'CIO',\n",
       " 'HR',\n",
       " 'NRG',\n",
       " 'CP',\n",
       " 'LOPE',\n",
       " 'DLA',\n",
       " 'PTI',\n",
       " 'JD',\n",
       " 'VFC',\n",
       " 'AFL',\n",
       " 'ALK',\n",
       " 'ABEV',\n",
       " 'AON',\n",
       " 'AJG',\n",
       " 'ASB',\n",
       " 'ALV',\n",
       " 'AVT',\n",
       " 'BHE',\n",
       " 'CCMP',\n",
       " 'COG',\n",
       " 'COF',\n",
       " 'CLS',\n",
       " 'CERN',\n",
       " 'CHTR',\n",
       " 'CVA',\n",
       " 'CUBE',\n",
       " 'DECK',\n",
       " 'DLX',\n",
       " 'UFS',\n",
       " 'EMN',\n",
       " 'EHTH',\n",
       " 'FHB',\n",
       " 'FSLR',\n",
       " 'FTV',\n",
       " 'FWRD',\n",
       " 'GLPG',\n",
       " 'GBX',\n",
       " 'HLI',\n",
       " 'HUN',\n",
       " 'ITW',\n",
       " 'ILMN',\n",
       " 'TILE',\n",
       " 'JNPR',\n",
       " 'KEX',\n",
       " 'LEA',\n",
       " 'LOGM',\n",
       " 'LPL',\n",
       " 'LPLA',\n",
       " 'MXL',\n",
       " 'MHK',\n",
       " 'OSIS',\n",
       " 'PEB',\n",
       " 'POWI',\n",
       " 'PFG',\n",
       " 'PFPT',\n",
       " 'PROS',\n",
       " 'RMD',\n",
       " 'TNET',\n",
       " 'UHS',\n",
       " 'VRSN',\n",
       " 'VCRA',\n",
       " 'VLRS',\n",
       " 'WRE',\n",
       " 'WERN',\n",
       " 'WY',\n",
       " 'WPP',\n",
       " 'FTI',\n",
       " 'FCN',\n",
       " 'KKR',\n",
       " 'KREF',\n",
       " 'CVS',\n",
       " 'FFIC',\n",
       " 'ARCE',\n",
       " 'BYSI',\n",
       " 'MD',\n",
       " 'TXMD',\n",
       " 'CABA',\n",
       " 'PGNY',\n",
       " 'TFFP',\n",
       " 'DAO',\n",
       " 'ADS',\n",
       " 'ACRS',\n",
       " 'SENS',\n",
       " 'BOOM',\n",
       " 'ANIK',\n",
       " 'CSLT',\n",
       " 'SPSC',\n",
       " 'PFNX',\n",
       " 'FET',\n",
       " 'MNKD',\n",
       " 'YNDX',\n",
       " 'HEXO',\n",
       " 'ENVA',\n",
       " 'SMSI',\n",
       " 'DRQ',\n",
       " 'NRZ',\n",
       " 'OMCL',\n",
       " 'SBCF',\n",
       " 'AXTA',\n",
       " 'HCM',\n",
       " 'CDAY',\n",
       " 'ED',\n",
       " 'DKS',\n",
       " 'SMG',\n",
       " 'FSB',\n",
       " 'GPC',\n",
       " 'HBAN',\n",
       " 'ODFL',\n",
       " 'PRLB',\n",
       " 'PLAN',\n",
       " 'COUP',\n",
       " 'ESSA',\n",
       " 'EPIX',\n",
       " 'GLPI',\n",
       " 'HRL',\n",
       " 'MGP',\n",
       " 'PAYC',\n",
       " 'PCTY',\n",
       " 'PPC',\n",
       " 'SAFM',\n",
       " 'WPC',\n",
       " 'PETS',\n",
       " 'ACC',\n",
       " 'BXS',\n",
       " 'CDNS',\n",
       " 'CE',\n",
       " 'ELS',\n",
       " 'HXL',\n",
       " 'HMST',\n",
       " 'RNST',\n",
       " 'TACO',\n",
       " 'ZION',\n",
       " 'ABG',\n",
       " 'GATX',\n",
       " 'JBLU',\n",
       " 'NUE',\n",
       " 'NVS',\n",
       " 'PCAR',\n",
       " 'PII',\n",
       " 'RF',\n",
       " 'SHW',\n",
       " 'SNV',\n",
       " 'CNI',\n",
       " 'CSL',\n",
       " 'IRBT',\n",
       " 'MANH',\n",
       " 'MPWR',\n",
       " 'MTH',\n",
       " 'TER',\n",
       " 'TXN',\n",
       " 'WHR',\n",
       " 'ABB',\n",
       " 'AVY',\n",
       " 'CLF',\n",
       " 'CMC',\n",
       " 'GWW',\n",
       " 'HRI',\n",
       " 'KNX',\n",
       " 'LAD',\n",
       " 'MHO',\n",
       " 'NSC',\n",
       " 'NTRS',\n",
       " 'BPOP',\n",
       " 'RCI',\n",
       " 'ROL',\n",
       " 'SLGN',\n",
       " 'SLAB',\n",
       " 'TDY',\n",
       " 'TMO',\n",
       " 'WM',\n",
       " 'WGO',\n",
       " 'AEM',\n",
       " 'ASGN',\n",
       " 'BCOV',\n",
       " 'CLGX',\n",
       " 'EBAY',\n",
       " 'ECHO',\n",
       " 'EW',\n",
       " 'EFX',\n",
       " 'FFIV',\n",
       " 'KNL',\n",
       " 'KRA',\n",
       " 'LSTR',\n",
       " 'LMAT',\n",
       " 'NTGR',\n",
       " 'ORLY',\n",
       " 'PKG',\n",
       " 'PYPL',\n",
       " 'SAVE',\n",
       " 'VAR',\n",
       " 'VMI',\n",
       " 'AB',\n",
       " 'BAX',\n",
       " 'CRS',\n",
       " 'CTXS',\n",
       " 'COWN',\n",
       " 'DHR',\n",
       " 'GPI',\n",
       " 'KIM',\n",
       " 'LH',\n",
       " 'MNRO',\n",
       " 'MSM',\n",
       " 'PTEN',\n",
       " 'ROP',\n",
       " 'RS',\n",
       " 'STM',\n",
       " 'SWK',\n",
       " 'TSCO',\n",
       " 'VLO',\n",
       " 'GRA',\n",
       " 'WST',\n",
       " 'BJRI',\n",
       " 'ELY',\n",
       " 'VTR',\n",
       " 'WETF',\n",
       " 'VG',\n",
       " 'NTR',\n",
       " 'AA',\n",
       " 'GSX',\n",
       " 'YELP',\n",
       " 'PING',\n",
       " 'RBS',\n",
       " 'MMS',\n",
       " 'EYPT',\n",
       " 'ALX',\n",
       " 'IEP',\n",
       " 'ETH',\n",
       " 'KGC',\n",
       " 'NEM',\n",
       " 'EGO',\n",
       " 'SNE',\n",
       " 'ESG',\n",
       " 'UTF',\n",
       " 'SLB',\n",
       " 'ELSE',\n",
       " 'MDB',\n",
       " 'NAV',\n",
       " 'HERO',\n",
       " 'IBB',\n",
       " 'MKTX',\n",
       " 'HI',\n",
       " 'WDAY',\n",
       " ...]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(foundsymbols))\n",
    "with open(\"foundsymbols.txt\",\"w\") as fh:\n",
    "  fh.write(\"\\n\".join(foundsymbols))\n",
    "foundsymbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34504 27603\n"
     ]
    }
   ],
   "source": [
    "#split into multiple corpus here\n",
    "\n",
    "\n",
    "import random\n",
    "random.shuffle(relevant_posts)\n",
    "n_train = int(0.8 * len(relevant_posts))\n",
    "\n",
    "training_posts = relevant_posts[:n_train]\n",
    "test_posts = relevant_posts[n_train:]\n",
    "val_posts = test_posts[:n_train//2]\n",
    "test_posts = test_posts[n_train//2:]\n",
    "\n",
    "vocab_input = [t[\"data\"][\"title\"]+\" \"+t[\"data\"][\"selftext\"] for t in training_posts]\n",
    "print(len(relevant_posts),n_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27603 13801\n",
      "6901\n",
      "3450\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3451"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_posts = relevant_posts[n_train:]\n",
    "print(n_train,n_train//2)\n",
    "test_posts = relevant_posts[n_train:]\n",
    "print(len(test_posts))\n",
    "print(len(test_posts)//2)\n",
    "val_posts = test_posts[:len(test_posts)//2]\n",
    "test_posts = test_posts[len(test_posts)//2:]\n",
    "len(test_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Proof you don’t need to know what you’re doing   \\n\\n![img](ftbthfhyniy31)\\n\\nI found this sub about 18 months ago and created my RH account 13 months ago. \\n\\nOptions\\n\\nI have no idea what I’m doing and because of that I typically look for options in the $100-$1,000 range. I play options off the industries I know and if I get a good or bad feeling. Then I look at the historical averages to see what’s feasible and I play my options further out (3-6-9 months). I go by the wsb theory of, “if it’s good enough to screenshot, it’s good enough to sell.” If I see an option go up 40%+, I sell, or I’ll sell enough to cover the initial purchase and let some ride (this is honestly the hardest part but just hit the sell button…if you start thinking, “well, what if…” then you’re in trouble). Most of the options I’ve sold for a profit go up even more, but I try not to look. For example, I bought 3 $160 calls (exp 3/20) on Disney for $248 a few weeks ago, today I sold one option at 300% and another at 500%. I’ll let the last one ride.\\n\\nDisclaimer: I do have 15 shares of Tesla with an average cost of $235 and 1 (free) share of CHK (up 5% to $0.70 today baby). Hoping people don't read this part because that's the only reason I've made money.\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 5000\n"
     ]
    }
   ],
   "source": [
    "vocab_size=5000\n",
    "\n",
    "vectorizer = CountVectorizer(input='content', analyzer='word', stop_words='english', tokenizer=LemmaTokenizer(), max_features=vocab_size, max_df=0.95, min_df=2)\n",
    "\n",
    "vectors = vectorizer.fit_transform(vocab_input)\n",
    "vocab_list = vectorizer.get_feature_names()\n",
    "print('vocab size:', len(vocab_list))\n",
    "idx = np.arange(vectors.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "vectors = vectors[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abbott',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'aboard',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absurd',\n",
       " 'abuse',\n",
       " 'accelerate',\n",
       " 'accelerated',\n",
       " 'accelerating',\n",
       " 'acceleration',\n",
       " 'accept',\n",
       " 'accepted',\n",
       " 'accepting',\n",
       " 'access',\n",
       " 'accessory',\n",
       " 'accident',\n",
       " 'accidentally',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'account',\n",
       " 'accounted',\n",
       " 'accounting',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'achieve',\n",
       " 'achieved',\n",
       " 'ackman',\n",
       " 'acquire',\n",
       " 'acquired',\n",
       " 'acquires',\n",
       " 'acquiring',\n",
       " 'acquisition',\n",
       " 'act',\n",
       " 'acted',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'active',\n",
       " 'actively',\n",
       " 'activision',\n",
       " 'activist',\n",
       " 'activity',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'ad',\n",
       " 'adam',\n",
       " 'adapt',\n",
       " 'add',\n",
       " 'added',\n",
       " 'addict',\n",
       " 'addicted',\n",
       " 'addiction',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additionally',\n",
       " 'address',\n",
       " 'adj',\n",
       " 'adjust',\n",
       " 'adjusted',\n",
       " 'adjustment',\n",
       " 'administration',\n",
       " 'admit',\n",
       " 'adoption',\n",
       " 'adult',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advantage',\n",
       " 'adverse',\n",
       " 'advertisement',\n",
       " 'advertiser',\n",
       " 'advertising',\n",
       " 'advice',\n",
       " 'advise',\n",
       " 'advised',\n",
       " 'advisor',\n",
       " 'advisory',\n",
       " 'aerospace',\n",
       " 'af',\n",
       " 'affect',\n",
       " 'affected',\n",
       " 'affecting',\n",
       " 'affiliate',\n",
       " 'afford',\n",
       " 'affordable',\n",
       " 'afloat',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'after-hours',\n",
       " 'after-market',\n",
       " 'afternoon',\n",
       " 'agency',\n",
       " 'agenda',\n",
       " 'agent',\n",
       " 'aggregate',\n",
       " 'aggressive',\n",
       " 'aggressively',\n",
       " 'agree',\n",
       " 'agreed',\n",
       " 'agreement',\n",
       " 'agrees',\n",
       " 'agricultural',\n",
       " 'agriculture',\n",
       " 'ah',\n",
       " 'ahead',\n",
       " 'ahead-',\n",
       " 'aid',\n",
       " 'aim',\n",
       " 'aimed',\n",
       " 'aiming',\n",
       " 'aint',\n",
       " 'airbus',\n",
       " 'aircraft',\n",
       " 'airline',\n",
       " 'airplane',\n",
       " 'airport',\n",
       " 'aka',\n",
       " 'alarm',\n",
       " 'albeit',\n",
       " 'album',\n",
       " 'alcohol',\n",
       " 'alert',\n",
       " 'algo',\n",
       " 'algorithm',\n",
       " 'algos',\n",
       " 'alibaba',\n",
       " 'alien',\n",
       " 'alike',\n",
       " 'alive',\n",
       " 'all-in',\n",
       " 'all-time',\n",
       " 'allegation',\n",
       " 'allegedly',\n",
       " 'alliance',\n",
       " 'allocation',\n",
       " 'allow',\n",
       " 'allowance',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'alongside',\n",
       " 'alpha',\n",
       " 'alphabet',\n",
       " 'alright',\n",
       " 'alternative',\n",
       " 'altria',\n",
       " 'am-',\n",
       " 'ama',\n",
       " 'amazing',\n",
       " 'amazon',\n",
       " 'america',\n",
       " 'american',\n",
       " 'ameritrade',\n",
       " 'amid',\n",
       " 'ammo',\n",
       " 'am|\\\\',\n",
       " 'anal',\n",
       " 'analog',\n",
       " 'analysis',\n",
       " 'analyst',\n",
       " 'analytics',\n",
       " 'analyze',\n",
       " 'analyzing',\n",
       " 'and/or',\n",
       " 'andrew',\n",
       " 'android',\n",
       " 'anecdotal',\n",
       " 'angry',\n",
       " 'animal',\n",
       " 'announce',\n",
       " 'announced',\n",
       " 'announcement',\n",
       " 'announces',\n",
       " 'announcing',\n",
       " 'annual',\n",
       " 'annualized',\n",
       " 'annually',\n",
       " 'answer',\n",
       " 'antibody',\n",
       " 'anticipate',\n",
       " 'anticipated',\n",
       " 'anticipating',\n",
       " 'anticipation',\n",
       " 'antitrust',\n",
       " 'antiviral',\n",
       " 'anxiety',\n",
       " 'anybody',\n",
       " 'anymore',\n",
       " 'anytime',\n",
       " 'anyways',\n",
       " 'aobc',\n",
       " 'apart',\n",
       " 'apartment',\n",
       " 'aphria',\n",
       " 'apocalypse',\n",
       " 'app',\n",
       " 'apparel',\n",
       " 'apparent',\n",
       " 'apparently',\n",
       " 'appeal',\n",
       " 'appear',\n",
       " 'appeared',\n",
       " 'appears',\n",
       " 'appl',\n",
       " 'apple',\n",
       " 'application',\n",
       " 'applied',\n",
       " 'applies',\n",
       " 'apply',\n",
       " 'applying',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'approach',\n",
       " 'approaching',\n",
       " 'appropriate',\n",
       " 'approval',\n",
       " 'approve',\n",
       " 'approved',\n",
       " 'approx',\n",
       " 'approximately',\n",
       " 'apr',\n",
       " 'april',\n",
       " 'apron',\n",
       " 'arabia',\n",
       " 'arbitrage',\n",
       " 'area',\n",
       " 'aren',\n",
       " 'arent',\n",
       " 'argentina',\n",
       " 'arguably',\n",
       " 'argue',\n",
       " 'argument',\n",
       " 'ark',\n",
       " 'arknet',\n",
       " 'arm',\n",
       " 'army',\n",
       " 'arrive',\n",
       " 'arrived',\n",
       " 'arrow',\n",
       " 'art',\n",
       " 'article',\n",
       " 'artificial',\n",
       " 'artificially',\n",
       " 'artist',\n",
       " 'asap',\n",
       " 'ascending',\n",
       " 'asia',\n",
       " 'asia-pacific',\n",
       " 'asian',\n",
       " 'aside',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'asks',\n",
       " 'aspect',\n",
       " 'ass',\n",
       " 'assessment',\n",
       " 'asset',\n",
       " 'asshole',\n",
       " 'assigned',\n",
       " 'assignment',\n",
       " 'assistance',\n",
       " 'associate',\n",
       " 'associated',\n",
       " 'association',\n",
       " 'assume',\n",
       " 'assumed',\n",
       " 'assuming',\n",
       " 'assumption',\n",
       " 'ate',\n",
       " 'aths',\n",
       " 'atleast',\n",
       " 'atm',\n",
       " 'attached',\n",
       " 'attack',\n",
       " 'attempt',\n",
       " 'attempted',\n",
       " 'attempting',\n",
       " 'attendance',\n",
       " 'attention',\n",
       " 'attorney',\n",
       " 'attract',\n",
       " 'attractive',\n",
       " 'auction',\n",
       " 'audience',\n",
       " 'august',\n",
       " 'aurora',\n",
       " 'australia',\n",
       " 'australian',\n",
       " 'author',\n",
       " 'authority',\n",
       " 'autism',\n",
       " 'autist',\n",
       " 'autistic',\n",
       " 'autists',\n",
       " 'auto=webp',\n",
       " 'automaker',\n",
       " 'automated',\n",
       " 'automatically',\n",
       " 'automation',\n",
       " 'automod',\n",
       " 'automotive',\n",
       " 'autonomous',\n",
       " 'autopilot',\n",
       " 'availability',\n",
       " 'available',\n",
       " 'average',\n",
       " 'averaged',\n",
       " 'averaging',\n",
       " 'avg',\n",
       " 'aviation',\n",
       " 'avoid',\n",
       " 'avoided',\n",
       " 'avoiding',\n",
       " 'award',\n",
       " 'awarded',\n",
       " 'aware',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'awful',\n",
       " 'awhile',\n",
       " 'aws',\n",
       " 'azure',\n",
       " 'b',\n",
       " 'baby',\n",
       " 'backed',\n",
       " 'background',\n",
       " 'backing',\n",
       " 'backlog',\n",
       " 'bad',\n",
       " 'badly',\n",
       " 'bae',\n",
       " 'bag',\n",
       " 'bagger',\n",
       " 'bagholding',\n",
       " 'baidu',\n",
       " 'bail',\n",
       " 'bailed',\n",
       " 'bailout',\n",
       " 'bailouts',\n",
       " 'baird',\n",
       " 'baked',\n",
       " 'balance',\n",
       " 'ball',\n",
       " 'ban',\n",
       " 'bancorp',\n",
       " 'band',\n",
       " 'bang',\n",
       " 'bank',\n",
       " 'banker',\n",
       " 'banking',\n",
       " 'bankroll',\n",
       " 'bankrupt',\n",
       " 'bankruptcy',\n",
       " 'banned',\n",
       " 'bar',\n",
       " 'bar_sector_m.png',\n",
       " 'bar_sector_q.png',\n",
       " 'bar_sector_t.png',\n",
       " 'bar_sector_w.png',\n",
       " 'bar_sector_y.png',\n",
       " 'bar_sector_ytd.png',\n",
       " 'barclays',\n",
       " 'barely',\n",
       " 'bargain',\n",
       " 'barrel',\n",
       " 'barrier',\n",
       " 'base',\n",
       " 'based',\n",
       " 'basement',\n",
       " 'basic',\n",
       " 'basically',\n",
       " 'basis',\n",
       " 'basket',\n",
       " 'bastard',\n",
       " 'bat',\n",
       " 'bath',\n",
       " 'bathroom',\n",
       " 'batman',\n",
       " 'battery',\n",
       " 'battle',\n",
       " 'bay',\n",
       " 'bb_20_2',\n",
       " 'bbb',\n",
       " 'beach',\n",
       " 'bear',\n",
       " 'bearish',\n",
       " 'beat',\n",
       " 'beaten',\n",
       " 'beating',\n",
       " 'beautiful',\n",
       " 'beauty',\n",
       " 'becky',\n",
       " 'bed',\n",
       " 'beef',\n",
       " 'beer',\n",
       " 'beerflu',\n",
       " 'beervirus',\n",
       " 'began',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'begun',\n",
       " 'behavior',\n",
       " 'beijing',\n",
       " 'belief',\n",
       " 'believe',\n",
       " 'believed',\n",
       " 'believing',\n",
       " 'bell',\n",
       " 'belong',\n",
       " 'benchmark',\n",
       " 'bend',\n",
       " 'beneficial',\n",
       " 'benefit',\n",
       " 'berkshire',\n",
       " 'bernie',\n",
       " 'bet',\n",
       " 'beta',\n",
       " 'better',\n",
       " 'betting',\n",
       " 'beverage',\n",
       " 'bezos',\n",
       " 'bias',\n",
       " 'bid',\n",
       " 'bid/ask',\n",
       " 'biden',\n",
       " 'bigger',\n",
       " 'biggest',\n",
       " 'bigly',\n",
       " 'bike',\n",
       " 'billion',\n",
       " 'billionaire',\n",
       " 'billy',\n",
       " 'biopharmaceutical',\n",
       " 'biotech',\n",
       " 'bird',\n",
       " 'birthday',\n",
       " 'bitch',\n",
       " 'bitching',\n",
       " 'bitcoin',\n",
       " 'bite',\n",
       " 'black',\n",
       " 'blackrock',\n",
       " 'blackstone',\n",
       " 'blah',\n",
       " 'blame',\n",
       " 'blast',\n",
       " 'bleed',\n",
       " 'bleeding',\n",
       " 'bless',\n",
       " 'blew',\n",
       " 'blind',\n",
       " 'blindly',\n",
       " 'blizzard',\n",
       " 'bln',\n",
       " 'block',\n",
       " 'blog',\n",
       " 'blood',\n",
       " 'bloodbath',\n",
       " 'bloody',\n",
       " 'bloomberg',\n",
       " 'blow',\n",
       " 'blowing',\n",
       " 'blown',\n",
       " 'board',\n",
       " 'boat',\n",
       " 'bob',\n",
       " 'body',\n",
       " 'boeing',\n",
       " 'bofa/merrill',\n",
       " 'boi',\n",
       " 'bois',\n",
       " 'bold',\n",
       " 'bomb',\n",
       " 'bond',\n",
       " 'bone',\n",
       " 'boner',\n",
       " 'bonus',\n",
       " 'book',\n",
       " 'booked',\n",
       " 'booking',\n",
       " 'boomer',\n",
       " 'booming',\n",
       " 'boost',\n",
       " 'boosted',\n",
       " 'boot',\n",
       " 'border',\n",
       " 'bored',\n",
       " 'boring',\n",
       " 'boris',\n",
       " 'born',\n",
       " 'borrow',\n",
       " 'borrowed',\n",
       " 'borrower',\n",
       " 'borrowing',\n",
       " 'bos',\n",
       " 'boston',\n",
       " 'bot',\n",
       " 'bother',\n",
       " 'bottle',\n",
       " 'bottom-line',\n",
       " 'bottomed',\n",
       " 'bought',\n",
       " 'bounce',\n",
       " 'bounced',\n",
       " 'bouncing',\n",
       " 'bound',\n",
       " 'bout',\n",
       " 'bowl',\n",
       " 'box',\n",
       " 'boy',\n",
       " 'boyfriend',\n",
       " 'bpd',\n",
       " 'bps',\n",
       " 'brain',\n",
       " 'branch',\n",
       " 'brand',\n",
       " 'branson',\n",
       " 'brazil',\n",
       " 'breach',\n",
       " 'bread',\n",
       " 'break',\n",
       " 'breakdown',\n",
       " 'breaker',\n",
       " 'breakeven',\n",
       " 'breakfast',\n",
       " 'breaking',\n",
       " 'breakout',\n",
       " 'breath',\n",
       " 'brent',\n",
       " 'brexit',\n",
       " 'brick',\n",
       " 'bridge',\n",
       " 'brief',\n",
       " 'briefing',\n",
       " 'briefing.com',\n",
       " 'briefly',\n",
       " 'bright',\n",
       " 'brilliant',\n",
       " 'bring',\n",
       " 'bringing',\n",
       " 'brings',\n",
       " 'british',\n",
       " 'broad',\n",
       " 'broader',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'broker',\n",
       " 'brokerage',\n",
       " 'bros',\n",
       " 'brother',\n",
       " 'brought',\n",
       " 'brrr',\n",
       " 'brrrr',\n",
       " 'btc',\n",
       " 'btfd',\n",
       " 'btw',\n",
       " 'bubble',\n",
       " 'buck',\n",
       " 'buddy',\n",
       " 'budget',\n",
       " 'buffet',\n",
       " 'buffett',\n",
       " 'build',\n",
       " 'building',\n",
       " 'built',\n",
       " 'bulk',\n",
       " 'bull',\n",
       " 'bullet',\n",
       " 'bullish',\n",
       " 'bullshit',\n",
       " 'bump',\n",
       " 'bunch',\n",
       " 'burden',\n",
       " 'burger',\n",
       " 'burn',\n",
       " 'burned',\n",
       " 'burning',\n",
       " 'burry',\n",
       " 'burst',\n",
       " 'bus',\n",
       " 'business',\n",
       " 'bust',\n",
       " 'buster',\n",
       " 'busy',\n",
       " 'butt',\n",
       " 'butterfly',\n",
       " 'button',\n",
       " 'buy',\n",
       " 'buyback',\n",
       " 'buyer',\n",
       " 'buying',\n",
       " 'buyout',\n",
       " 'buzz',\n",
       " 'bye',\n",
       " 'ca',\n",
       " 'cable',\n",
       " 'cad',\n",
       " 'caesar',\n",
       " 'cagr',\n",
       " 'calculate',\n",
       " 'calculated',\n",
       " 'calculation',\n",
       " 'calculator',\n",
       " 'calendar',\n",
       " 'calendar**',\n",
       " 'california',\n",
       " 'call/put',\n",
       " 'called',\n",
       " 'calling',\n",
       " 'calls/puts',\n",
       " 'came',\n",
       " 'camera',\n",
       " 'campaign',\n",
       " 'canada',\n",
       " 'canadian',\n",
       " 'cancel',\n",
       " 'canceled',\n",
       " 'canceling',\n",
       " 'cancellation',\n",
       " 'cancelled',\n",
       " 'cancelling',\n",
       " 'cancer',\n",
       " 'candidate',\n",
       " 'candle',\n",
       " 'candy',\n",
       " 'cannabis',\n",
       " 'canopy',\n",
       " 'cap',\n",
       " 'capability',\n",
       " 'capable',\n",
       " 'capacity',\n",
       " 'capex',\n",
       " 'capital',\n",
       " 'capitalism',\n",
       " 'capitalize',\n",
       " 'capped',\n",
       " 'capture',\n",
       " 'carbon',\n",
       " 'card',\n",
       " 'care',\n",
       " 'career',\n",
       " 'careful',\n",
       " 'carefully',\n",
       " 'cargo',\n",
       " 'caribbean',\n",
       " 'carnival',\n",
       " 'carried',\n",
       " 'carrier',\n",
       " 'carry',\n",
       " 'carrying',\n",
       " 'case',\n",
       " 'cashed',\n",
       " 'cashing',\n",
       " 'casino',\n",
       " 'casual',\n",
       " 'catalyst',\n",
       " 'catch',\n",
       " 'catching',\n",
       " 'category',\n",
       " 'caught',\n",
       " 'cause',\n",
       " 'caused',\n",
       " 'causing',\n",
       " 'caution',\n",
       " 'cautious',\n",
       " 'cbs',\n",
       " 'cd',\n",
       " 'cdos',\n",
       " 'ceiling',\n",
       " 'celebrate',\n",
       " 'cell',\n",
       " 'cent',\n",
       " 'center',\n",
       " 'central',\n",
       " 'century',\n",
       " 'ceo',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'certainty',\n",
       " 'chad',\n",
       " 'chain',\n",
       " 'chair',\n",
       " 'chairman',\n",
       " 'challenge',\n",
       " 'challenging',\n",
       " 'chamber',\n",
       " 'chance',\n",
       " 'change',\n",
       " 'changed',\n",
       " 'changing',\n",
       " 'channel',\n",
       " 'chaos',\n",
       " 'chapter',\n",
       " 'charge',\n",
       " 'charged',\n",
       " 'charging',\n",
       " 'charity',\n",
       " 'charles',\n",
       " 'chart',\n",
       " 'charter',\n",
       " 'chase',\n",
       " 'chasing',\n",
       " 'chat',\n",
       " 'cheap',\n",
       " 'cheaper',\n",
       " 'cheat',\n",
       " 'check',\n",
       " 'checked',\n",
       " 'checking',\n",
       " 'cheer',\n",
       " 'cheese',\n",
       " 'chegg',\n",
       " 'chemical',\n",
       " 'chesapeake',\n",
       " 'chewy',\n",
       " 'chicago',\n",
       " 'chicken',\n",
       " 'chief',\n",
       " 'child',\n",
       " 'chill',\n",
       " 'china',\n",
       " 'china\\\\',\n",
       " 'chinese',\n",
       " 'chip',\n",
       " 'chipotle',\n",
       " 'chk',\n",
       " 'choice',\n",
       " 'choose',\n",
       " 'choosing',\n",
       " 'choppy',\n",
       " 'chose',\n",
       " 'chosen',\n",
       " 'christ',\n",
       " 'christmas',\n",
       " 'chronic',\n",
       " 'chunk',\n",
       " 'church',\n",
       " 'churn',\n",
       " 'circle',\n",
       " 'circuit',\n",
       " 'circumstance',\n",
       " 'cisco',\n",
       " 'cited',\n",
       " 'citi',\n",
       " 'citigroup',\n",
       " 'citing',\n",
       " 'citizen',\n",
       " 'citron',\n",
       " 'city',\n",
       " 'civil',\n",
       " 'claim',\n",
       " 'claimed',\n",
       " 'claiming',\n",
       " 'clarify',\n",
       " 'clarity',\n",
       " 'class',\n",
       " 'classic',\n",
       " 'clean',\n",
       " 'cleaning',\n",
       " 'clear',\n",
       " 'cleared',\n",
       " 'clearing',\n",
       " 'clearly',\n",
       " 'click',\n",
       " 'client',\n",
       " 'cliff',\n",
       " 'climate',\n",
       " 'climb',\n",
       " 'climbed',\n",
       " 'climbing',\n",
       " 'clinic',\n",
       " 'clinical',\n",
       " 'clorox',\n",
       " 'close',\n",
       " 'closed',\n",
       " 'closely',\n",
       " 'closer',\n",
       " 'closest',\n",
       " 'closing',\n",
       " 'closure',\n",
       " 'clothes',\n",
       " 'clothing',\n",
       " 'cloud',\n",
       " 'cloud-based',\n",
       " 'cloudflare',\n",
       " 'clown',\n",
       " 'clue',\n",
       " 'cnbc',\n",
       " 'cnbc.com',\n",
       " 'cnn',\n",
       " 'co.',\n",
       " 'coal',\n",
       " 'coast',\n",
       " 'cocaine',\n",
       " 'cock',\n",
       " 'cod',\n",
       " 'code',\n",
       " 'coffee',\n",
       " 'cohort',\n",
       " 'coin',\n",
       " 'coincidence',\n",
       " 'collaboration',\n",
       " 'collapse',\n",
       " 'collapsed',\n",
       " 'collapsing',\n",
       " 'collar',\n",
       " 'collateral',\n",
       " 'collect',\n",
       " 'collected',\n",
       " 'collecting',\n",
       " 'collection',\n",
       " 'collective',\n",
       " 'collectively',\n",
       " 'college',\n",
       " 'color',\n",
       " 'com',\n",
       " 'combat',\n",
       " 'combination',\n",
       " 'combine',\n",
       " 'combined',\n",
       " 'comcast',\n",
       " 'come',\n",
       " 'comeback',\n",
       " 'comfort',\n",
       " 'comfortable',\n",
       " 'coming',\n",
       " 'comment',\n",
       " 'commentary',\n",
       " 'commented',\n",
       " 'commerce',\n",
       " 'commercial',\n",
       " 'commission',\n",
       " 'commit',\n",
       " 'commitment',\n",
       " 'committed',\n",
       " 'committee',\n",
       " 'commodity',\n",
       " 'common',\n",
       " 'communication',\n",
       " 'communist',\n",
       " 'community',\n",
       " 'comp',\n",
       " 'company',\n",
       " 'comparable',\n",
       " 'compare',\n",
       " 'compared',\n",
       " 'comparing',\n",
       " 'comparison',\n",
       " 'compelling',\n",
       " 'compensation',\n",
       " 'compete',\n",
       " 'competent',\n",
       " 'competing',\n",
       " 'competition',\n",
       " 'competitive',\n",
       " 'competitor',\n",
       " 'complain',\n",
       " 'complaining',\n",
       " 'complaint',\n",
       " 'complete',\n",
       " 'completed',\n",
       " 'completely',\n",
       " 'completion',\n",
       " 'complex',\n",
       " 'compliance',\n",
       " 'complicated',\n",
       " 'comply',\n",
       " 'component',\n",
       " 'composite',\n",
       " 'compound',\n",
       " 'compounded',\n",
       " 'comprehensive',\n",
       " 'computer',\n",
       " 'computing',\n",
       " 'concept',\n",
       " 'concern',\n",
       " 'concerned',\n",
       " 'concerning',\n",
       " 'concert',\n",
       " 'concluded',\n",
       " 'conclusion',\n",
       " 'condition',\n",
       " 'condor',\n",
       " 'conduct',\n",
       " 'conducted',\n",
       " 'conference',\n",
       " 'confidence',\n",
       " 'confident',\n",
       " 'confirm',\n",
       " 'confirmation',\n",
       " 'confirmed',\n",
       " 'confirms',\n",
       " 'conflict',\n",
       " 'confused',\n",
       " 'confusing',\n",
       " 'congrats',\n",
       " 'congratulation',\n",
       " 'congress',\n",
       " 'congressional',\n",
       " 'connect',\n",
       " 'connected',\n",
       " 'connection',\n",
       " 'consecutive',\n",
       " 'consensus',\n",
       " 'consequence',\n",
       " 'conservative',\n",
       " 'consider',\n",
       " 'consideration',\n",
       " 'considered',\n",
       " 'considering',\n",
       " 'consisted',\n",
       " 'consistent',\n",
       " 'consistently',\n",
       " 'consists',\n",
       " 'console',\n",
       " 'consolidated',\n",
       " 'consolidation',\n",
       " 'conspiracy',\n",
       " 'constant',\n",
       " 'constantly',\n",
       " 'constellation',\n",
       " 'construction',\n",
       " 'consulting',\n",
       " 'consumer',\n",
       " 'consumption',\n",
       " 'contact',\n",
       " 'contain',\n",
       " 'contained',\n",
       " 'container',\n",
       " 'containment',\n",
       " 'contains',\n",
       " 'contango',\n",
       " 'content',\n",
       " 'contest',\n",
       " 'context',\n",
       " 'continually',\n",
       " 'continuation',\n",
       " 'continue',\n",
       " 'continued',\n",
       " 'continues',\n",
       " 'continuing',\n",
       " 'continuously',\n",
       " 'contract',\n",
       " 'contracted',\n",
       " 'contracting',\n",
       " 'contraction',\n",
       " 'contractor',\n",
       " 'contrarian',\n",
       " 'contrary',\n",
       " 'contrast',\n",
       " 'contribute',\n",
       " 'contributed',\n",
       " 'contributing',\n",
       " 'contribution',\n",
       " 'control',\n",
       " 'controlled',\n",
       " 'controlling',\n",
       " 'conversation',\n",
       " 'conversion',\n",
       " 'convert',\n",
       " 'converted',\n",
       " 'convertible',\n",
       " 'conviction',\n",
       " 'convince',\n",
       " 'convinced',\n",
       " 'cook',\n",
       " 'cooking',\n",
       " 'cool',\n",
       " 'copper',\n",
       " 'copy',\n",
       " 'corn',\n",
       " 'corner',\n",
       " 'corona',\n",
       " 'coronavirus',\n",
       " 'corp',\n",
       " 'corp.',\n",
       " 'corporate',\n",
       " 'corporation',\n",
       " 'correct',\n",
       " 'correction',\n",
       " 'correctly',\n",
       " 'correlated',\n",
       " 'correlation',\n",
       " 'cost',\n",
       " 'costco',\n",
       " 'cough',\n",
       " 'couldn',\n",
       " 'count',\n",
       " 'counter',\n",
       " 'counting',\n",
       " 'countless',\n",
       " 'country',\n",
       " 'county',\n",
       " 'couple',\n",
       " 'coupled',\n",
       " 'coupon',\n",
       " 'course',\n",
       " ...]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [####################] 100.0%\n",
      "27603\n"
     ]
    }
   ],
   "source": [
    "threshhold=.05\n",
    "lt = LemmaTokenizer()\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def calculateData(post):\n",
    "    #print(post)\n",
    "    data=post[\"data\"]\n",
    "    thesesymbols=post[\"symbols\"]\n",
    "    text = data[\"title\"]+\" \"+data[\"selftext\"]\n",
    "    texttokens=lt(text)\n",
    "    #print(text,texttokens)\n",
    "    #print(\"Symbol:\",thesesymbols)\n",
    "    wordvector=[]\n",
    "    for word in vocab_list:\n",
    "        wordvector.append(texttokens.count(word))\n",
    "    returnarray=[]\n",
    "    for symbolmap in thesesymbols:\n",
    "        symbol=list(symbolmap.keys())[0]\n",
    "        try:\n",
    "        #if True:\n",
    "            \n",
    "                #if word in texttokens:\n",
    "                    #print(word)\n",
    "                #    wordvector.append(1)\n",
    "                #else:\n",
    "                #    wordvector.append(0)\n",
    "                #locword = text.find(word)\n",
    "                #distance=0\n",
    "                #if locword>-1:\n",
    "                #    distance=abs(text.find(symbolmap[symbol])-locword)\n",
    "                #    print(symbol,word,distance)\n",
    "                #wordvector.append(distance)\n",
    "            #print(symbol,wordvector)\n",
    "            posttime=[0,0,0,0]\n",
    "            start=ET.localize(datetime.datetime.fromtimestamp(data[\"created_utc\"]))\n",
    "            if start.hour>=21:\n",
    "                posttime[0]=1\n",
    "            elif start.hour < 5:\n",
    "                posttime[0]=1\n",
    "            elif start.hour < 9:\n",
    "                posttime[1]=1\n",
    "            elif start.hour < 16:\n",
    "                posttime[2]=1\n",
    "            else:\n",
    "                posttime[3]=1\n",
    "            if start.hour>=9:\n",
    "              start=start+datetime.timedelta(days=1)\n",
    "            start=start.replace(hour=9,minute=0,second=0,microsecond=0).date()\n",
    "            end=start+dt\n",
    "            startprice=getstockprice(symbol,start)\n",
    "            endprice=getstockprice(symbol,end)\n",
    "            #print(start,end,history)\n",
    "            delta=(endprice-startprice)/startprice\n",
    "            if delta<=-1*(threshhold):\n",
    "                result=1\n",
    "            elif delta>=threshhold:\n",
    "                result=2\n",
    "                #print(symbol,delta,result,wordvector)\n",
    "            else:\n",
    "                result=0\n",
    "            returnarray.append([result]+posttime+wordvector)\n",
    "        except Exception as err:\n",
    "            print(\"Error with\",symbol,\", skipping this one:\",err)\n",
    "    return returnarray\n",
    "\n",
    "\n",
    "\n",
    "training_vector = []\n",
    "i=0\n",
    "for posts in training_posts:\n",
    "    #try:\n",
    "    if True:\n",
    "       response=calculateData(posts)\n",
    "       for row in response:\n",
    "            training_vector.append(row)\n",
    "    #except Exception as err:\n",
    "    #    print(\"Error\",err)\n",
    "    #    pass\n",
    "    i+=1\n",
    "    if(round(i/100,0)==i/100):\n",
    "        update_progress(i / len(training_posts))\n",
    "        print(len(training_posts))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Output</th>\n",
       "      <th>21-4</th>\n",
       "      <th>5-8</th>\n",
       "      <th>9-15</th>\n",
       "      <th>16-20</th>\n",
       "      <th>abbott</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>aboard</th>\n",
       "      <th>absolute</th>\n",
       "      <th>...</th>\n",
       "      <th>yr/yr</th>\n",
       "      <th>ytd</th>\n",
       "      <th>yuan</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zero</th>\n",
       "      <th>zillow</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zynga</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68581</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68582</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68583</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68584</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68585</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68586 rows × 5005 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Output  21-4  5-8  9-15  16-20  abbott  ability  able  aboard  \\\n",
       "0           2     1    0     0      0       0        0     0       0   \n",
       "1           2     1    0     0      0       0        0     0       0   \n",
       "2           1     0    0     0      1       0        0     0       0   \n",
       "3           1     1    0     0      0       0        1     0       0   \n",
       "4           2     1    0     0      0       0        1     0       0   \n",
       "...       ...   ...  ...   ...    ...     ...      ...   ...     ...   \n",
       "68581       0     0    0     0      1       0        0     0       0   \n",
       "68582       1     0    0     0      1       0        0     0       0   \n",
       "68583       2     1    0     0      0       0        0     0       0   \n",
       "68584       2     1    0     0      0       0        0     0       0   \n",
       "68585       2     1    0     0      0       0        0     0       0   \n",
       "\n",
       "       absolute  ...  yr/yr  ytd  yuan  zealand  zero  zillow  zombie  zone  \\\n",
       "0             0  ...      0    0     0        0     0       0       0     0   \n",
       "1             0  ...      0    0     0        0     0       0       0     0   \n",
       "2             0  ...      0    0     0        0     0       0       0     0   \n",
       "3             0  ...      0    0     0        0     0       0       0     0   \n",
       "4             0  ...      0    0     0        0     0       0       0     0   \n",
       "...         ...  ...    ...  ...   ...      ...   ...     ...     ...   ...   \n",
       "68581         0  ...      0    0     0        0     0       0       0     0   \n",
       "68582         0  ...      0    0     0        0     0       0       0     0   \n",
       "68583         0  ...      0    0     0        0     0       0       0     0   \n",
       "68584         0  ...      0    0     0        0     0       0       0     0   \n",
       "68585         0  ...      0    0     0        0     0       0       0     0   \n",
       "\n",
       "       zoom  zynga  \n",
       "0         0      0  \n",
       "1         0      0  \n",
       "2         0      0  \n",
       "3         0      0  \n",
       "4         0      0  \n",
       "...     ...    ...  \n",
       "68581     0      0  \n",
       "68582     0      0  \n",
       "68583     0      0  \n",
       "68584     0      0  \n",
       "68585     0      0  \n",
       "\n",
       "[68586 rows x 5005 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(training_vector, columns=[\"Output\"]+[\"21-4\",\"5-8\",\"9-15\",\"16-20\"]+vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded training data location: s3://sagemaker-us-east-1-011113936377/wsb-training/train/wsb-data\n",
      "training artifacts will be uploaded to: s3://sagemaker-us-east-1-011113936377/wsb-training/output\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker.amazon.common as smac\n",
    "import io\n",
    "\n",
    "np_training_vector = np.array(training_vector).astype('float32')\n",
    "\n",
    "buf = io.BytesIO()\n",
    "smac.write_numpy_to_dense_tensor(buf, np_training_vector[:,1:], np_training_vector[:,0])\n",
    "buf.seek(0)\n",
    "\n",
    "prefix = 'wsb-training'\n",
    "key= 'wsb-data'\n",
    "boto3.resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train', key)).upload_fileobj(buf)\n",
    "s3_train_data = 's3://{}/{}/train/{}'.format(bucket, prefix, key)\n",
    "print('uploaded training data location: {}'.format(s3_train_data))\n",
    "\n",
    "\n",
    "output_location = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "print('training artifacts will be uploaded to: {}'.format(output_location))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-11 11:24:11 Starting - Starting the training job...\n",
      "2020-08-11 11:24:13 Starting - Launching requested ML instances......\n",
      "2020-08-11 11:25:27 Starting - Preparing the instances for training.........\n",
      "2020-08-11 11:26:56 Downloading - Downloading input data...\n",
      "2020-08-11 11:27:32 Training - Downloading the training image..\n",
      "2020-08-11 11:27:54 Training - Training image download completed. Training in progress.\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[08/11/2020 11:27:59 INFO 140556035622720] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'loss_insensitivity': u'0.01', u'epochs': u'15', u'feature_dim': u'auto', u'init_bias': u'0.0', u'lr_scheduler_factor': u'auto', u'num_calibration_samples': u'10000000', u'accuracy_top_k': u'3', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'num_point_for_scaler': u'10000', u'_log_level': u'info', u'quantile': u'0.5', u'bias_lr_mult': u'auto', u'lr_scheduler_step': u'auto', u'init_method': u'uniform', u'init_sigma': u'0.01', u'lr_scheduler_minimum_lr': u'auto', u'target_recall': u'0.8', u'num_models': u'auto', u'early_stopping_patience': u'3', u'momentum': u'auto', u'unbias_label': u'auto', u'wd': u'auto', u'optimizer': u'auto', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.001', u'learning_rate': u'auto', u'_kvstore': u'auto', u'normalize_data': u'true', u'binary_classifier_model_selection_criteria': u'accuracy', u'use_lr_scheduler': u'true', u'target_precision': u'0.8', u'unbias_data': u'auto', u'init_scale': u'0.07', u'bias_wd_mult': u'auto', u'f_beta': u'1.0', u'mini_batch_size': u'1000', u'huber_delta': u'1.0', u'num_classes': u'1', u'beta_1': u'auto', u'loss': u'auto', u'beta_2': u'auto', u'_enable_profiler': u'false', u'normalize_label': u'auto', u'_num_gpus': u'auto', u'balance_multiclass_weights': u'false', u'positive_example_weight_mult': u'1.0', u'l1': u'auto', u'margin': u'1.0'}\u001b[0m\n",
      "\u001b[34m[08/11/2020 11:27:59 INFO 140556035622720] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {u'feature_dim': u'5004', u'mini_batch_size': u'200', u'predictor_type': u'multiclass_classifier', u'num_classes': u'3'}\u001b[0m\n",
      "\u001b[34m[08/11/2020 11:27:59 INFO 140556035622720] Final configuration: {u'loss_insensitivity': u'0.01', u'epochs': u'15', u'feature_dim': u'5004', u'init_bias': u'0.0', u'lr_scheduler_factor': u'auto', u'num_calibration_samples': u'10000000', u'accuracy_top_k': u'3', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'num_point_for_scaler': u'10000', u'_log_level': u'info', u'quantile': u'0.5', u'bias_lr_mult': u'auto', u'lr_scheduler_step': u'auto', u'init_method': u'uniform', u'init_sigma': u'0.01', u'lr_scheduler_minimum_lr': u'auto', u'target_recall': u'0.8', u'num_models': u'auto', u'early_stopping_patience': u'3', u'momentum': u'auto', u'unbias_label': u'auto', u'wd': u'auto', u'optimizer': u'auto', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.001', u'learning_rate': u'auto', u'_kvstore': u'auto', u'normalize_data': u'true', u'binary_classifier_model_selection_criteria': u'accuracy', u'use_lr_scheduler': u'true', u'target_precision': u'0.8', u'unbias_data': u'auto', u'init_scale': u'0.07', u'bias_wd_mult': u'auto', u'f_beta': u'1.0', u'mini_batch_size': u'200', u'huber_delta': u'1.0', u'num_classes': u'3', u'predictor_type': u'multiclass_classifier', u'beta_1': u'auto', u'loss': u'auto', u'beta_2': u'auto', u'_enable_profiler': u'false', u'normalize_label': u'auto', u'_num_gpus': u'auto', u'balance_multiclass_weights': u'false', u'positive_example_weight_mult': u'1.0', u'l1': u'auto', u'margin': u'1.0'}\u001b[0m\n",
      "\u001b[34m[08/11/2020 11:27:59 WARNING 140556035622720] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[08/11/2020 11:27:59 INFO 140556035622720] Using default worker.\u001b[0m\n",
      "\u001b[34m[08/11/2020 11:27:59 INFO 140556035622720] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[2020-08-11 11:28:00.026] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 48, \"num_examples\": 1, \"num_bytes\": 4013600}\u001b[0m\n",
      "\u001b[34m[08/11/2020 11:28:00 INFO 140556035622720] Create Store: local\u001b[0m\n",
      "\u001b[34m[2020-08-11 11:28:01.411] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 1384, \"num_examples\": 51, \"num_bytes\": 204693600}\u001b[0m\n",
      "\u001b[34m[08/11/2020 11:28:01 INFO 140556035622720] Scaler algorithm parameters\n",
      " <algorithm.scaler.ScalerAlgorithmStable object at 0x7fd5617a23d0>\u001b[0m\n",
      "\u001b[34m[08/11/2020 11:28:01 INFO 140556035622720] Scaling model computed with parameters:\n",
      " {'stdev_weight': \u001b[0m\n",
      "\u001b[34m[0.45506707 0.24215004 0.47690797 ... 0.10914983 0.26352328 0.12554377]\u001b[0m\n",
      "\u001b[34m<NDArray 5004 @cpu(0)>, 'stdev_label': None, 'mean_label': None, 'mean_weight': \u001b[0m\n",
      "\u001b[34m[0.2928432  0.06254902 0.34980395 ... 0.00686275 0.03078432 0.01480392]\u001b[0m\n",
      "\u001b[34m<NDArray 5004 @cpu(0)>}\u001b[0m\n",
      "\u001b[34m[08/11/2020 11:28:01 INFO 140556035622720] nvidia-smi took: 0.0251920223236 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[08/11/2020 11:28:01 INFO 140556035622720] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[08/11/2020 11:28:01 WARNING 140556035622720] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[08/11/2020 11:28:01 WARNING 140556035622720] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[08/11/2020 11:28:01 WARNING 140556035622720] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[08/11/2020 11:28:01 WARNING 140556035622720] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[08/11/2020 11:28:01 WARNING 140556035622720] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[08/11/2020 11:28:01 WARNING 140556035622720] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[08/11/2020 11:28:01 WARNING 140556035622720] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[08/11/2020 11:28:01 WARNING 140556035622720] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[08/11/2020 11:28:01 WARNING 140556035622720] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[08/11/2020 11:28:01 WARNING 140556035622720] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[08/11/2020 11:28:01 WARNING 140556035622720] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[08/11/2020 11:28:01 WARNING 140556035622720] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[08/11/2020 11:28:01 WARNING 140556035622720] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[08/11/2020 11:28:01 WARNING 140556035622720] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[08/11/2020 11:28:01 WARNING 140556035622720] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[08/11/2020 11:28:01 WARNING 140556035622720] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[08/11/2020 11:28:01 WARNING 140556035622720] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[08/11/2020 11:28:01 WARNING 140556035622720] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[08/11/2020 11:28:01 WARNING 140556035622720] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[08/11/2020 11:28:01 WARNING 140556035622720] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[08/11/2020 11:28:01 WARNING 140556035622720] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 51, \"sum\": 51.0, \"min\": 51}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 52, \"sum\": 52.0, \"min\": 52}, \"Total Records Seen\": {\"count\": 1, \"max\": 10400, \"sum\": 10400.0, \"min\": 10400}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 10200, \"sum\": 10200.0, \"min\": 10200}, \"Reset Count\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}}, \"EndTime\": 1597145281.663948, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\"}, \"StartTime\": 1597145281.663915}\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "container = get_image_uri(boto3.Session().region_name, 'linear-learner')\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "linear = sagemaker.estimator.Estimator(container,\n",
    "                                       role, \n",
    "                                       train_instance_count=1, \n",
    "                                       train_instance_type='ml.m4.10xlarge',\n",
    "                                       output_path=output_location,\n",
    "                                       sagemaker_session=session)\n",
    "linear.set_hyperparameters(feature_dim=len(vocab_list)+4,\n",
    "                           predictor_type='multiclass_classifier',\n",
    "                           num_classes=3,\n",
    "                           mini_batch_size=200)\n",
    "\n",
    "linear.fit({'train': s3_train_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'linear' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d1ee44a76e55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m linear_predictor = linear.deploy(initial_instance_count=1,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                  instance_type='ml.m4.10xlarge')\n",
      "\u001b[0;31mNameError\u001b[0m: name 'linear' is not defined"
     ]
    }
   ],
   "source": [
    "linear_predictor = linear.deploy(initial_instance_count=1,\n",
    "                                 instance_type='ml.m4.10xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vector = []\n",
    "i=0\n",
    "for posts in test_posts:\n",
    "    #try:\n",
    "    if True:\n",
    "       response=calculateData(posts)\n",
    "       for row in response:\n",
    "            test_vector.append(row)\n",
    "    #except Exception as err:\n",
    "    #    print(\"Error\",err)\n",
    "    #    pass\n",
    "    i+=1\n",
    "    if True:\n",
    "        update_progress(i / len(test_posts))\n",
    "        print(len(test_posts))\n",
    "np_test_vector = np.array(test_vector).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import csv_serializer, json_deserializer\n",
    "\n",
    "linear_predictor.content_type = 'text/csv'\n",
    "linear_predictor.serializer = csv_serializer\n",
    "linear_predictor.deserializer = json_deserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_test_vector[:4,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = linear_predictor.predict(np_training_vector[:4,1:])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "predictions = []\n",
    "for array in np.array_split(np_test_vector[:,1:], 100):\n",
    "    #print(array)\n",
    "    result = linear_predictor.predict(array)\n",
    "    #print(result)\n",
    "    predictions += [r['predicted_label'] for r in result['predictions']]\n",
    "#print(predictions)\n",
    "predictions = np.array(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels=[]\n",
    "for value in np_test_vector[:,0]:\n",
    "    #print(value[0])\n",
    "    test_labels.append(value)\n",
    "print(len(test_labels),len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.crosstab([test_labels], predictions, rownames=['actuals'], colnames=['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "def error_rate(predictions, labels):\n",
    "    \"\"\"Return the error rate and confusions.\"\"\"\n",
    "    correct = numpy.sum(predictions == labels)\n",
    "    total = predictions.shape[0]\n",
    "\n",
    "    error = 100.0 - (100 * float(correct) / float(total))\n",
    "\n",
    "    confusions = numpy.zeros([3,3], numpy.int32)\n",
    "    bundled = zip(predictions, labels)\n",
    "    for predicted, actual in bundled:\n",
    "        confusions[int(predicted), int(actual)] += 1\n",
    "    \n",
    "    return error, confusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "NUM_LABELS = 3  # change it according to num_class in your dataset\n",
    "test_error, confusions = error_rate(numpy.asarray(predictions), numpy.asarray(test_labels))\n",
    "print('Test error: %.1f%%' % test_error)\n",
    "\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.grid(False)\n",
    "plt.xticks(numpy.arange(NUM_LABELS))\n",
    "plt.yticks(numpy.arange(NUM_LABELS))\n",
    "plt.imshow(confusions, cmap=plt.cm.jet, interpolation='nearest');\n",
    "\n",
    "for i, cas in enumerate(confusions):\n",
    "    for j, count in enumerate(cas):\n",
    "        if count > 0:\n",
    "            xoff = .07 * len(str(count))\n",
    "            plt.text(j-xoff, i+.2, int(count), fontsize=9, color='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sklearn.metrics.f1_score(numpy.asarray(test_labels),numpy.asarray(predictions),average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.recall_score(numpy.asarray(test_labels),numpy.asarray(predictions),average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.precision_score(numpy.asarray(test_labels),numpy.asarray(predictions),average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sklearn.metrics.classification_report(numpy.asarray(test_labels),numpy.asarray(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker.Session().delete_endpoint(linear_predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
