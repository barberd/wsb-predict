{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-1-011113936377\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "session = sagemaker.Session()\n",
    "bucket = session.default_bucket()\n",
    "\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 sync s3://{bucket}/wsb/data/ data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import pytz\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "token_pattern = re.compile(r\"(?u)\\b\\w\\w+\\b\")\n",
    "\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc.lower()) if len(t) >= 2 and re.match(\"[a-z].*\",t) \n",
    "                and re.match(token_pattern, t) and t.upper() not in allsymbols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ET = pytz.timezone('US/Eastern')\n",
    "\n",
    "ignorelist=[\"DD\",\"FREE\",\"CASH\",\"ON\",\"I\"]\n",
    "allsymbols=[]\n",
    "with open(\"allsymbols.txt\") as fh:\n",
    "    allsymbols=fh.readlines()\n",
    "allsymbols = [x.strip() for x in allsymbols]\n",
    "\n",
    "dt=datetime.timedelta(days=7)\n",
    "\n",
    "wnl = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, sys\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def update_progress(progress):\n",
    "    bar_length = 20\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "\n",
    "    block = int(round(bar_length * progress))\n",
    "\n",
    "    clear_output(wait = True)\n",
    "    text = \"Progress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "stockdata={}\n",
    "def getstockprice(symbol,date):\n",
    "    if symbol not in stockdata:\n",
    "        with open(\"stockprices/\"+symbol,\"r\") as fh:\n",
    "            data=json.load(fh)\n",
    "        stockdata[symbol]={}\n",
    "        for stockday in data:\n",
    "            indate=datetime.datetime.strptime(stockday[\"begins_at\"],\"%Y-%m-%dT%H:%M:%SZ\").date()\n",
    "            stockdata[symbol][indate]=stockday\n",
    "    today=datetime.date.today()\n",
    "    while True:\n",
    "        #print(date)\n",
    "        if date in stockdata[symbol]:\n",
    "            return float(stockdata[symbol][date]['close_price'])\n",
    "        date=date+datetime.timedelta(days=1)\n",
    "        if date>today:\n",
    "            break\n",
    "    raise Exception(\"No stock data found\")\n",
    "    return None\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [####################] 99.9%\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(\"data/\")\n",
    "\n",
    "foundsymbols=[]\n",
    "relevant_posts = []\n",
    "i=0\n",
    "for file in files:\n",
    "  if(round(i/100,0)==i/100):\n",
    "        update_progress(i / len(files))  \n",
    "  with open(\"data/\"+file,\"r\") as fh:\n",
    "    try:\n",
    "        data=json.load(fh)\n",
    "        text = (data[\"title\"]+\" \"+data[\"selftext\"]).replace('\\\"','').replace('\\'','')\n",
    "        allmatches=[]\n",
    "        matches=re.findall('\\W*([A-Z][A-Z\\.]{0,3})\\W',text)\n",
    "        for submatch in matches:\n",
    "            allmatches.append({submatch:submatch})\n",
    "            #pass\n",
    "        matches2=re.findall('\\W*(\\$[a-z\\.]{1,4})',text)\n",
    "        for submatch in matches2:\n",
    "            allmatches.append({submatch.upper()[1:]:submatch})\n",
    "        thesesymbols=[]\n",
    "        #print(allmatches)\n",
    "        for submatch in allmatches:\n",
    "            symbol=list(submatch.keys())[0]\n",
    "            #print(submatch.keys())\n",
    "            #print(symbol)\n",
    "            #print([list(x.keys())[0] for x in thesesymbols])\n",
    "            if symbol in allsymbols and symbol not in [list(x.keys())[0] for x in thesesymbols] and symbol not in ignorelist:\n",
    "                thesesymbols.append(submatch)\n",
    "                if symbol not in foundsymbols:\n",
    "                    foundsymbols.append(symbol)\n",
    "        if len(thesesymbols)>0:\n",
    "            relevant_posts.append({\"data\":data,\"symbols\":thesesymbols})\n",
    "            #print(thesesymbols)\n",
    "    except Exception as err:\n",
    "      print(\"Error with\",file)\n",
    "      raise(err)\n",
    "  i+=1\n",
    "    \n",
    "\n",
    "  #if i>1000:\n",
    "  #  break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3661\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['TSLA',\n",
       " 'B',\n",
       " 'AMZN',\n",
       " 'COST',\n",
       " 'C',\n",
       " 'LULU',\n",
       " 'AMD',\n",
       " 'FB',\n",
       " 'PTON',\n",
       " 'AAPL',\n",
       " 'GOLD',\n",
       " 'ROKU',\n",
       " 'NFLX',\n",
       " 'DIS',\n",
       " 'HAS',\n",
       " 'GOOD',\n",
       " 'ONCY',\n",
       " 'SPCE',\n",
       " 'AMC',\n",
       " 'KR',\n",
       " 'PM',\n",
       " 'ABC',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'CYBR',\n",
       " 'PANW',\n",
       " 'RPD',\n",
       " 'EDIT',\n",
       " 'DTE',\n",
       " 'DCOM',\n",
       " 'AT',\n",
       " 'ACB',\n",
       " 'THC',\n",
       " 'MU',\n",
       " 'IP',\n",
       " 'AG',\n",
       " 'GILD',\n",
       " 'TJX',\n",
       " 'HTZ',\n",
       " 'TVTY',\n",
       " 'DGX',\n",
       " 'QQQ',\n",
       " 'TA',\n",
       " 'BYND',\n",
       " 'POST',\n",
       " 'SR',\n",
       " 'NIO',\n",
       " 'RING',\n",
       " 'A',\n",
       " 'NEW',\n",
       " 'IT',\n",
       " 'FOSL',\n",
       " 'BK',\n",
       " 'PINS',\n",
       " 'KRTX',\n",
       " 'OVID',\n",
       " 'DOW',\n",
       " 'SBUX',\n",
       " 'VC',\n",
       " 'MCD',\n",
       " 'MSFT',\n",
       " 'WMT',\n",
       " 'SNAP',\n",
       " 'PECK',\n",
       " 'HUGE',\n",
       " 'GDP',\n",
       " 'WELL',\n",
       " 'CDC',\n",
       " 'BA',\n",
       " 'V',\n",
       " 'FAT',\n",
       " 'NOC',\n",
       " 'LMT',\n",
       " 'RH',\n",
       " 'AAL',\n",
       " 'GO',\n",
       " 'SDC',\n",
       " 'ALGN',\n",
       " 'ONE',\n",
       " 'ATVI',\n",
       " 'M',\n",
       " 'CEO',\n",
       " 'K',\n",
       " 'ALLY',\n",
       " 'SIX',\n",
       " 'CME',\n",
       " 'AM',\n",
       " 'LIVE',\n",
       " 'FIT',\n",
       " 'SWBI',\n",
       " 'EC',\n",
       " 'F',\n",
       " 'CRM',\n",
       " 'BAC',\n",
       " 'CTO',\n",
       " 'PEP',\n",
       " 'UAL',\n",
       " 'DAL',\n",
       " 'JNJ',\n",
       " 'PCG',\n",
       " 'E',\n",
       " 'PLUS',\n",
       " 'AMTD',\n",
       " 'TTD',\n",
       " 'DEA',\n",
       " 'CBD',\n",
       " 'CCL',\n",
       " 'ARE',\n",
       " 'OUT',\n",
       " 'G',\n",
       " 'BMO',\n",
       " 'IONS',\n",
       " 'FOR',\n",
       " 'HAL',\n",
       " 'INFY',\n",
       " 'KO',\n",
       " 'SYF',\n",
       " 'NDAQ',\n",
       " 'NEE',\n",
       " 'ERIC',\n",
       " 'DPZ',\n",
       " 'LUV',\n",
       " 'UNP',\n",
       " 'AXP',\n",
       " 'SNY',\n",
       " 'NEXT',\n",
       " 'MMM',\n",
       " 'UPS',\n",
       " 'CAT',\n",
       " 'TRU',\n",
       " 'HOG',\n",
       " 'APPS',\n",
       " 'ELLO',\n",
       " 'LOAN',\n",
       " 'VZ',\n",
       " 'APHA',\n",
       " 'R',\n",
       " 'SO',\n",
       " 'MGM',\n",
       " 'T',\n",
       " 'ROCK',\n",
       " 'SSSS',\n",
       " 'LAND',\n",
       " 'AI',\n",
       " 'III',\n",
       " 'PLUG',\n",
       " 'EOD',\n",
       " 'ULTA',\n",
       " 'GM',\n",
       " 'BBBY',\n",
       " 'CPRX',\n",
       " 'TD',\n",
       " 'CLX',\n",
       " 'TH',\n",
       " 'ARCH',\n",
       " 'BE',\n",
       " 'KHC',\n",
       " 'PG',\n",
       " 'SHOP',\n",
       " 'TQQQ',\n",
       " 'ETSY',\n",
       " 'TSM',\n",
       " 'BSX',\n",
       " 'PE',\n",
       " 'GF',\n",
       " 'FCEL',\n",
       " 'NVDA',\n",
       " 'GPS',\n",
       " 'FT',\n",
       " 'GME',\n",
       " 'BIG',\n",
       " 'HPQ',\n",
       " 'HP',\n",
       " 'UBER',\n",
       " 'BY',\n",
       " 'ANY',\n",
       " 'ALKS',\n",
       " 'ALL',\n",
       " 'NOW',\n",
       " 'STAY',\n",
       " 'CFA',\n",
       " 'BABA',\n",
       " 'ACAD',\n",
       " 'KSS',\n",
       " 'CROX',\n",
       " 'IBM',\n",
       " 'IR',\n",
       " 'JP',\n",
       " 'DFS',\n",
       " 'LL',\n",
       " 'DB',\n",
       " 'SQ',\n",
       " 'MTCH',\n",
       " 'ATH',\n",
       " 'USA',\n",
       " 'OR',\n",
       " 'SELF',\n",
       " 'INO',\n",
       " 'TWO',\n",
       " 'UI',\n",
       " 'NMI',\n",
       " 'NMIH',\n",
       " 'WTI',\n",
       " 'CL',\n",
       " 'IOVA',\n",
       " 'LN',\n",
       " 'L',\n",
       " 'PD',\n",
       " 'CAR',\n",
       " 'SMFG',\n",
       " 'ZM',\n",
       " 'JPM',\n",
       " 'CFO',\n",
       " 'EVER',\n",
       " 'KL',\n",
       " 'WPM',\n",
       " 'SSRM',\n",
       " 'GEO',\n",
       " 'XLNX',\n",
       " 'EAST',\n",
       " 'CSCO',\n",
       " 'PSA',\n",
       " 'TWTR',\n",
       " 'ENPH',\n",
       " 'ALLT',\n",
       " 'GAIN',\n",
       " 'O',\n",
       " 'D',\n",
       " 'H',\n",
       " 'ZNGA',\n",
       " 'AUPH',\n",
       " 'PCIM',\n",
       " 'PS',\n",
       " 'GNUS',\n",
       " 'DBX',\n",
       " 'HSBC',\n",
       " 'UNIT',\n",
       " 'AIMT',\n",
       " 'BBY',\n",
       " 'LYFT',\n",
       " 'GOOG',\n",
       " 'OXY',\n",
       " 'IMO',\n",
       " 'DHT',\n",
       " 'TNK',\n",
       " 'FRO',\n",
       " 'NAT',\n",
       " 'SA',\n",
       " 'TV',\n",
       " 'DVD',\n",
       " 'RGR',\n",
       " 'RAD',\n",
       " 'J',\n",
       " 'AYI',\n",
       " 'KB',\n",
       " 'KBH',\n",
       " 'WD',\n",
       " 'WDFC',\n",
       " 'ADES',\n",
       " 'XP',\n",
       " 'AGTC',\n",
       " 'AMAG',\n",
       " 'SMPL',\n",
       " 'LB',\n",
       " 'AZZ',\n",
       " 'XRX',\n",
       " 'VOYA',\n",
       " 'BLK',\n",
       " 'PDT',\n",
       " 'BAM',\n",
       " 'KTOS',\n",
       " 'IQ',\n",
       " 'TEVA',\n",
       " 'MO',\n",
       " 'BUD',\n",
       " 'PRT',\n",
       " 'ES',\n",
       " 'WORK',\n",
       " 'CMG',\n",
       " 'PPT',\n",
       " 'BRO',\n",
       " 'APA',\n",
       " 'DXC',\n",
       " 'DISH',\n",
       " 'SNR',\n",
       " 'FIVE',\n",
       " 'NI',\n",
       " 'KMI',\n",
       " 'OSG',\n",
       " 'STNG',\n",
       " 'EURN',\n",
       " 'OSTK',\n",
       " 'EA',\n",
       " 'TS',\n",
       " 'YY',\n",
       " 'MAR',\n",
       " 'PAR',\n",
       " 'ET',\n",
       " 'TLRY',\n",
       " 'SQQQ',\n",
       " 'ESNT',\n",
       " 'PLC',\n",
       " 'UBS',\n",
       " 'ALLK',\n",
       " 'LOGI',\n",
       " 'BIDU',\n",
       " 'ANET',\n",
       " 'CRWD',\n",
       " 'CAN',\n",
       " 'PZZA',\n",
       " 'WEN',\n",
       " 'HEAR',\n",
       " 'JACK',\n",
       " 'Z',\n",
       " 'ZS',\n",
       " 'ABIO',\n",
       " 'TGT',\n",
       " 'DKNG',\n",
       " 'MS',\n",
       " 'REAL',\n",
       " 'WOW',\n",
       " 'CGC',\n",
       " 'FSLY',\n",
       " 'CTL',\n",
       " 'ICD',\n",
       " 'PNC',\n",
       " 'APRN',\n",
       " 'TDA',\n",
       " 'SHAK',\n",
       " 'HD',\n",
       " 'WKHS',\n",
       " 'VCEL',\n",
       " 'MDWD',\n",
       " 'VFF',\n",
       " 'DOCU',\n",
       " 'EB',\n",
       " 'TCOM',\n",
       " 'XOM',\n",
       " 'AAOI',\n",
       " 'RCL',\n",
       " 'PLNT',\n",
       " 'MSB',\n",
       " 'W',\n",
       " 'PHAT',\n",
       " 'GE',\n",
       " 'STZ',\n",
       " 'FDX',\n",
       " 'EV',\n",
       " 'GL',\n",
       " 'FL',\n",
       " 'SRPT',\n",
       " 'SLDB',\n",
       " 'STMP',\n",
       " 'NTNX',\n",
       " 'SRNE',\n",
       " 'PHD',\n",
       " 'SCI',\n",
       " 'TTWO',\n",
       " 'NHC',\n",
       " 'SE',\n",
       " 'RNG',\n",
       " 'LOCO',\n",
       " 'DLTR',\n",
       " 'AIG',\n",
       " 'TAL',\n",
       " 'DE',\n",
       " 'DXCM',\n",
       " 'APT',\n",
       " 'NKLA',\n",
       " 'FCF',\n",
       " 'HOME',\n",
       " 'TELL',\n",
       " 'TLT',\n",
       " 'MIND',\n",
       " 'CNA',\n",
       " 'WINS',\n",
       " 'TREE',\n",
       " 'MTD',\n",
       " 'KRP',\n",
       " 'WFC',\n",
       " 'GS',\n",
       " 'UNH',\n",
       " 'INTC',\n",
       " 'BIIB',\n",
       " 'HCA',\n",
       " 'BOH',\n",
       " 'MTB',\n",
       " 'ONB',\n",
       " 'SAP',\n",
       " 'BMRC',\n",
       " 'CMA',\n",
       " 'PHG',\n",
       " 'CBU',\n",
       " 'KMB',\n",
       " 'TFC',\n",
       " 'PLD',\n",
       " 'LII',\n",
       " 'LLY',\n",
       " 'SNA',\n",
       " 'LVS',\n",
       " 'TRV',\n",
       " 'LRCX',\n",
       " 'KALU',\n",
       " 'EMR',\n",
       " 'CIT',\n",
       " 'FITB',\n",
       " 'BG',\n",
       " 'VIR',\n",
       " 'MRNA',\n",
       " 'CODX',\n",
       " 'APEX',\n",
       " 'BB',\n",
       " 'CARV',\n",
       " 'MOMO',\n",
       " 'NVO',\n",
       " 'LNG',\n",
       " 'USAC',\n",
       " 'DAX',\n",
       " 'EARS',\n",
       " 'CZR',\n",
       " 'AN',\n",
       " 'EYE',\n",
       " 'MA',\n",
       " 'ATR',\n",
       " 'GT',\n",
       " 'MRK',\n",
       " 'PT',\n",
       " 'KN',\n",
       " 'JCO',\n",
       " 'UTI',\n",
       " 'CVM',\n",
       " 'AZN',\n",
       " 'GD',\n",
       " 'SGA',\n",
       " 'TTNP',\n",
       " 'FLAT',\n",
       " 'NG',\n",
       " 'MTNB',\n",
       " 'ALGT',\n",
       " 'IRL',\n",
       " 'ARDS',\n",
       " 'WASH',\n",
       " 'WH',\n",
       " 'CO',\n",
       " 'FOX',\n",
       " 'LE',\n",
       " 'VEEV',\n",
       " 'SAFE',\n",
       " 'ISRG',\n",
       " 'TDOC',\n",
       " 'ST',\n",
       " 'WIX',\n",
       " 'FCX',\n",
       " 'CUZ',\n",
       " 'ASRT',\n",
       " 'VAC',\n",
       " 'TMUS',\n",
       " 'VSTO',\n",
       " 'SPR',\n",
       " 'RMED',\n",
       " 'OLN',\n",
       " 'UXIN',\n",
       " 'KEYS',\n",
       " 'MASI',\n",
       " 'RTX',\n",
       " 'CHGG',\n",
       " 'SP',\n",
       " 'IRS',\n",
       " 'CSX',\n",
       " 'BBW',\n",
       " 'ING',\n",
       " 'RVLV',\n",
       " 'CAC',\n",
       " 'MAN',\n",
       " 'BR',\n",
       " 'THO',\n",
       " 'AVGO',\n",
       " 'HRB',\n",
       " 'PLAY',\n",
       " 'HDS',\n",
       " 'LOVE',\n",
       " 'CHS',\n",
       " 'TLRD',\n",
       " 'SECO',\n",
       " 'DLTH',\n",
       " 'SHLO',\n",
       " 'ASNA',\n",
       " 'CPST',\n",
       " 'JW.A',\n",
       " 'AZRE',\n",
       " 'ADXS',\n",
       " 'CASY',\n",
       " 'LMNR',\n",
       " 'BBCP',\n",
       " 'NEPT',\n",
       " 'OXM',\n",
       " 'SPCB',\n",
       " 'TMDX',\n",
       " 'TUFN',\n",
       " 'LIVX',\n",
       " 'RENN',\n",
       " 'SMMT',\n",
       " 'CRWS',\n",
       " 'UROV',\n",
       " 'CHWY',\n",
       " 'CAKE',\n",
       " 'API',\n",
       " 'FSD',\n",
       " 'ACA',\n",
       " 'CI',\n",
       " 'ANTM',\n",
       " 'HUM',\n",
       " 'MOH',\n",
       " 'CNC',\n",
       " 'NCLH',\n",
       " 'TWNK',\n",
       " 'CARS',\n",
       " 'BBVA',\n",
       " 'JWN',\n",
       " 'HBI',\n",
       " 'FOXA',\n",
       " 'AEO',\n",
       " 'SKX',\n",
       " 'URBN',\n",
       " 'PAGS',\n",
       " 'NAVI',\n",
       " 'CMD',\n",
       " 'PENN',\n",
       " 'VERY',\n",
       " 'TVIX',\n",
       " 'ZIV',\n",
       " 'CBOE',\n",
       " 'PUMP',\n",
       " 'MOD',\n",
       " 'PBPB',\n",
       " 'PCB',\n",
       " 'ITCI',\n",
       " 'PSX',\n",
       " 'MFA',\n",
       " 'TAP',\n",
       " 'DEO',\n",
       " 'SEAS',\n",
       " 'TX',\n",
       " 'AVTR',\n",
       " 'JMIA',\n",
       " 'TLSA',\n",
       " 'HE',\n",
       " 'GRPN',\n",
       " 'SINO',\n",
       " 'HSY',\n",
       " 'XRAY',\n",
       " 'MRVL',\n",
       " 'RYTM',\n",
       " 'GPRO',\n",
       " 'ASX',\n",
       " 'EFT',\n",
       " 'CLB',\n",
       " 'ICE',\n",
       " 'NC',\n",
       " 'HA',\n",
       " 'HLT',\n",
       " 'IMAX',\n",
       " 'AR',\n",
       " 'KMX',\n",
       " 'AZO',\n",
       " 'IBEX',\n",
       " 'BGCP',\n",
       " 'INFO',\n",
       " 'MANU',\n",
       " 'UN',\n",
       " 'FDP',\n",
       " 'FLR',\n",
       " 'TOT',\n",
       " 'IBP',\n",
       " 'RILY',\n",
       " 'UNVR',\n",
       " 'PDD',\n",
       " 'VER',\n",
       " 'PLMR',\n",
       " 'SASR',\n",
       " 'OPRT',\n",
       " 'ZEAL',\n",
       " 'MRTX',\n",
       " 'RL',\n",
       " 'SCCO',\n",
       " 'WYNN',\n",
       " 'AIMC',\n",
       " 'BX',\n",
       " 'CLVS',\n",
       " 'CCO',\n",
       " 'CORT',\n",
       " 'ETM',\n",
       " 'GPN',\n",
       " 'GTN',\n",
       " 'IPG',\n",
       " 'KRYS',\n",
       " 'NBSE',\n",
       " 'NXST',\n",
       " 'OMC',\n",
       " 'SSP',\n",
       " 'SBBP',\n",
       " 'SBGI',\n",
       " 'TGNA',\n",
       " 'TXG',\n",
       " 'JBL',\n",
       " 'NEOG',\n",
       " 'CMTL',\n",
       " 'CTAS',\n",
       " 'NKE',\n",
       " 'SNX',\n",
       " 'DAVA',\n",
       " 'WOR',\n",
       " 'AIR',\n",
       " 'FUL',\n",
       " 'ACN',\n",
       " 'CAG',\n",
       " 'GDS',\n",
       " 'CAMP',\n",
       " 'MTN',\n",
       " 'PRGS',\n",
       " 'UEPS',\n",
       " 'ATOM',\n",
       " 'TC',\n",
       " 'CPA',\n",
       " 'CTV',\n",
       " 'QCOM',\n",
       " 'FVRR',\n",
       " 'FLIR',\n",
       " 'RELL',\n",
       " 'PLOW',\n",
       " 'OKE',\n",
       " 'ALLO',\n",
       " 'CMO',\n",
       " 'CR',\n",
       " 'PSC',\n",
       " 'COO',\n",
       " 'IDE',\n",
       " 'RE',\n",
       " 'FLY',\n",
       " 'BW',\n",
       " 'EH',\n",
       " 'NOK',\n",
       " 'ALB',\n",
       " 'ATNM',\n",
       " 'OPK',\n",
       " 'NAK',\n",
       " 'KT',\n",
       " 'PBR',\n",
       " 'ONVO',\n",
       " 'OI',\n",
       " 'RST',\n",
       " 'UL',\n",
       " 'CBNK',\n",
       " 'GRUB',\n",
       " 'PEG',\n",
       " 'ROK',\n",
       " 'TEAM',\n",
       " 'AC',\n",
       " 'VALE',\n",
       " 'BHP',\n",
       " 'SRG',\n",
       " 'VNO',\n",
       " 'CLDR',\n",
       " 'NET',\n",
       " 'AFYA',\n",
       " 'TY',\n",
       " 'AMG',\n",
       " 'CRMD',\n",
       " 'GGAL',\n",
       " 'BMA',\n",
       " 'SUPV',\n",
       " 'BBAR',\n",
       " 'BCH',\n",
       " 'SIRI',\n",
       " 'APRE',\n",
       " 'AUY',\n",
       " 'SWN',\n",
       " 'OKTA',\n",
       " 'DK',\n",
       " 'DVAX',\n",
       " 'NCR',\n",
       " 'FLEX',\n",
       " 'AVD',\n",
       " 'ECL',\n",
       " 'SD',\n",
       " 'TSN',\n",
       " 'COMM',\n",
       " 'FTC',\n",
       " 'RBC',\n",
       " 'CM',\n",
       " 'IEX',\n",
       " 'GENE',\n",
       " 'RAND',\n",
       " 'PRO',\n",
       " 'HPE',\n",
       " 'CARE',\n",
       " 'IVR',\n",
       " 'TDW',\n",
       " 'TYG',\n",
       " 'EAT',\n",
       " 'SAGE',\n",
       " 'RETA',\n",
       " 'BMRN',\n",
       " 'ALXN',\n",
       " 'REGN',\n",
       " 'RGNX',\n",
       " 'RARE',\n",
       " 'GSK',\n",
       " 'BMY',\n",
       " 'ABBV',\n",
       " 'AMGN',\n",
       " 'SGEN',\n",
       " 'FORD',\n",
       " 'LONE',\n",
       " 'SMH',\n",
       " 'FANG',\n",
       " 'BBC',\n",
       " 'ARCT',\n",
       " 'BNTX',\n",
       " 'HTBX',\n",
       " 'VXRT',\n",
       " 'BCS',\n",
       " 'INCY',\n",
       " 'MLM',\n",
       " 'MIC',\n",
       " 'MYGN',\n",
       " 'TRUP',\n",
       " 'PFD',\n",
       " 'TAK',\n",
       " 'MYL',\n",
       " 'TIF',\n",
       " 'HIBB',\n",
       " 'ORCL',\n",
       " 'CAH',\n",
       " 'NYT',\n",
       " 'DG',\n",
       " 'LEG',\n",
       " 'RUN',\n",
       " 'NATH',\n",
       " 'KIDS',\n",
       " 'TOPS',\n",
       " 'ABT',\n",
       " 'PRPL',\n",
       " 'CC',\n",
       " 'AMED',\n",
       " 'BKNG',\n",
       " 'SEE',\n",
       " 'HON',\n",
       " 'NR',\n",
       " 'CFR',\n",
       " 'WWE',\n",
       " 'ADI',\n",
       " 'PEY',\n",
       " 'ESPR',\n",
       " 'JAN',\n",
       " 'ETFC',\n",
       " 'HONE',\n",
       " 'EARN',\n",
       " 'CIO',\n",
       " 'HR',\n",
       " 'NRG',\n",
       " 'CP',\n",
       " 'LOPE',\n",
       " 'DLA',\n",
       " 'PTI',\n",
       " 'JD',\n",
       " 'VFC',\n",
       " 'AFL',\n",
       " 'ALK',\n",
       " 'ABEV',\n",
       " 'AON',\n",
       " 'AJG',\n",
       " 'ASB',\n",
       " 'ALV',\n",
       " 'AVT',\n",
       " 'BHE',\n",
       " 'CCMP',\n",
       " 'COG',\n",
       " 'COF',\n",
       " 'CLS',\n",
       " 'CERN',\n",
       " 'CHTR',\n",
       " 'CVA',\n",
       " 'CUBE',\n",
       " 'DECK',\n",
       " 'DLX',\n",
       " 'UFS',\n",
       " 'EMN',\n",
       " 'EHTH',\n",
       " 'FHB',\n",
       " 'FSLR',\n",
       " 'FTV',\n",
       " 'FWRD',\n",
       " 'GLPG',\n",
       " 'GBX',\n",
       " 'HLI',\n",
       " 'HUN',\n",
       " 'ITW',\n",
       " 'ILMN',\n",
       " 'TILE',\n",
       " 'JNPR',\n",
       " 'KEX',\n",
       " 'LEA',\n",
       " 'LOGM',\n",
       " 'LPL',\n",
       " 'LPLA',\n",
       " 'MXL',\n",
       " 'MHK',\n",
       " 'OSIS',\n",
       " 'PEB',\n",
       " 'POWI',\n",
       " 'PFG',\n",
       " 'PFPT',\n",
       " 'PROS',\n",
       " 'RMD',\n",
       " 'TNET',\n",
       " 'UHS',\n",
       " 'VRSN',\n",
       " 'VCRA',\n",
       " 'VLRS',\n",
       " 'WRE',\n",
       " 'WERN',\n",
       " 'WY',\n",
       " 'WPP',\n",
       " 'FTI',\n",
       " 'FCN',\n",
       " 'KKR',\n",
       " 'KREF',\n",
       " 'CVS',\n",
       " 'FFIC',\n",
       " 'ARCE',\n",
       " 'BYSI',\n",
       " 'MD',\n",
       " 'TXMD',\n",
       " 'CABA',\n",
       " 'PGNY',\n",
       " 'TFFP',\n",
       " 'DAO',\n",
       " 'ADS',\n",
       " 'ACRS',\n",
       " 'SENS',\n",
       " 'BOOM',\n",
       " 'ANIK',\n",
       " 'CSLT',\n",
       " 'SPSC',\n",
       " 'PFNX',\n",
       " 'FET',\n",
       " 'MNKD',\n",
       " 'YNDX',\n",
       " 'HEXO',\n",
       " 'ENVA',\n",
       " 'SMSI',\n",
       " 'DRQ',\n",
       " 'NRZ',\n",
       " 'OMCL',\n",
       " 'SBCF',\n",
       " 'AXTA',\n",
       " 'HCM',\n",
       " 'CDAY',\n",
       " 'ED',\n",
       " 'DKS',\n",
       " 'SMG',\n",
       " 'FSB',\n",
       " 'GPC',\n",
       " 'HBAN',\n",
       " 'ODFL',\n",
       " 'PRLB',\n",
       " 'PLAN',\n",
       " 'COUP',\n",
       " 'ESSA',\n",
       " 'EPIX',\n",
       " 'GLPI',\n",
       " 'HRL',\n",
       " 'MGP',\n",
       " 'PAYC',\n",
       " 'PCTY',\n",
       " 'PPC',\n",
       " 'SAFM',\n",
       " 'WPC',\n",
       " 'PETS',\n",
       " 'ACC',\n",
       " 'BXS',\n",
       " 'CDNS',\n",
       " 'CE',\n",
       " 'ELS',\n",
       " 'HXL',\n",
       " 'HMST',\n",
       " 'RNST',\n",
       " 'TACO',\n",
       " 'ZION',\n",
       " 'ABG',\n",
       " 'GATX',\n",
       " 'JBLU',\n",
       " 'NUE',\n",
       " 'NVS',\n",
       " 'PCAR',\n",
       " 'PII',\n",
       " 'RF',\n",
       " 'SHW',\n",
       " 'SNV',\n",
       " 'CNI',\n",
       " 'CSL',\n",
       " 'IRBT',\n",
       " 'MANH',\n",
       " 'MPWR',\n",
       " 'MTH',\n",
       " 'TER',\n",
       " 'TXN',\n",
       " 'WHR',\n",
       " 'ABB',\n",
       " 'AVY',\n",
       " 'CLF',\n",
       " 'CMC',\n",
       " 'GWW',\n",
       " 'HRI',\n",
       " 'KNX',\n",
       " 'LAD',\n",
       " 'MHO',\n",
       " 'NSC',\n",
       " 'NTRS',\n",
       " 'BPOP',\n",
       " 'RCI',\n",
       " 'ROL',\n",
       " 'SLGN',\n",
       " 'SLAB',\n",
       " 'TDY',\n",
       " 'TMO',\n",
       " 'WM',\n",
       " 'WGO',\n",
       " 'AEM',\n",
       " 'ASGN',\n",
       " 'BCOV',\n",
       " 'CLGX',\n",
       " 'EBAY',\n",
       " 'ECHO',\n",
       " 'EW',\n",
       " 'EFX',\n",
       " 'FFIV',\n",
       " 'KNL',\n",
       " 'KRA',\n",
       " 'LSTR',\n",
       " 'LMAT',\n",
       " 'NTGR',\n",
       " 'ORLY',\n",
       " 'PKG',\n",
       " 'PYPL',\n",
       " 'SAVE',\n",
       " 'VAR',\n",
       " 'VMI',\n",
       " 'AB',\n",
       " 'BAX',\n",
       " 'CRS',\n",
       " 'CTXS',\n",
       " 'COWN',\n",
       " 'DHR',\n",
       " 'GPI',\n",
       " 'KIM',\n",
       " 'LH',\n",
       " 'MNRO',\n",
       " 'MSM',\n",
       " 'PTEN',\n",
       " 'ROP',\n",
       " 'RS',\n",
       " 'STM',\n",
       " 'SWK',\n",
       " 'TSCO',\n",
       " 'VLO',\n",
       " 'GRA',\n",
       " 'WST',\n",
       " 'BJRI',\n",
       " 'ELY',\n",
       " 'VTR',\n",
       " 'WETF',\n",
       " 'VG',\n",
       " 'NTR',\n",
       " 'AA',\n",
       " 'GSX',\n",
       " 'YELP',\n",
       " 'PING',\n",
       " 'RBS',\n",
       " 'MMS',\n",
       " 'EYPT',\n",
       " 'ALX',\n",
       " 'IEP',\n",
       " 'ETH',\n",
       " 'KGC',\n",
       " 'NEM',\n",
       " 'EGO',\n",
       " 'SNE',\n",
       " 'ESG',\n",
       " 'UTF',\n",
       " 'SLB',\n",
       " 'ELSE',\n",
       " 'MDB',\n",
       " 'NAV',\n",
       " 'HERO',\n",
       " 'IBB',\n",
       " 'MKTX',\n",
       " 'HI',\n",
       " 'WDAY',\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(foundsymbols))\n",
    "with open(\"foundsymbols.txt\",\"w\") as fh:\n",
    "    fh.write(\"\\n\".join(foundsymbols))\n",
    "foundsymbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34504 27603\n"
     ]
    }
   ],
   "source": [
    "#split into multiple corpus here\n",
    "\n",
    "\n",
    "import random\n",
    "random.shuffle(relevant_posts)\n",
    "n_train = int(0.8 * len(relevant_posts))\n",
    "\n",
    "training_posts = relevant_posts[:n_train]\n",
    "test_posts = relevant_posts[n_train:]\n",
    "val_posts = test_posts[:n_train//2]\n",
    "test_posts = test_posts[n_train//2:]\n",
    "\n",
    "vocab_input = [t[\"data\"][\"title\"]+\" \"+t[\"data\"][\"selftext\"] for t in training_posts]\n",
    "print(len(relevant_posts),n_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27603 13801\n",
      "6901\n",
      "3450\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3451"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_posts = relevant_posts[n_train:]\n",
    "print(n_train,n_train//2)\n",
    "test_posts = relevant_posts[n_train:]\n",
    "print(len(test_posts))\n",
    "print(len(test_posts)//2)\n",
    "val_posts = test_posts[:len(test_posts)//2]\n",
    "test_posts = test_posts[len(test_posts)//2:]\n",
    "len(test_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['le', 'u', 'wa'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 2500\n"
     ]
    }
   ],
   "source": [
    "vocab_size=2500\n",
    "\n",
    "vectorizer = CountVectorizer(input='content', analyzer='word', stop_words='english', tokenizer=LemmaTokenizer(), max_features=vocab_size, max_df=0.95, min_df=2)\n",
    "\n",
    "vectors = vectorizer.fit_transform(vocab_input)\n",
    "vocab_list = vectorizer.get_feature_names()\n",
    "print('vocab size:', len(vocab_list))\n",
    "idx = np.arange(vectors.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "vectors = vectors[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ability',\n",
       " 'able',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'accept',\n",
       " 'access',\n",
       " 'according',\n",
       " 'account',\n",
       " 'accounting',\n",
       " 'accurate',\n",
       " 'acquire',\n",
       " 'acquired',\n",
       " 'acquisition',\n",
       " 'action',\n",
       " 'active',\n",
       " 'actively',\n",
       " 'activision',\n",
       " 'activity',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'ad',\n",
       " 'add',\n",
       " 'added',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additionally',\n",
       " 'address',\n",
       " 'adj',\n",
       " 'adjusted',\n",
       " 'administration',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advantage',\n",
       " 'advertising',\n",
       " 'advice',\n",
       " 'advisor',\n",
       " 'af',\n",
       " 'affect',\n",
       " 'affected',\n",
       " 'afford',\n",
       " 'after-hours',\n",
       " 'after-market',\n",
       " 'afternoon',\n",
       " 'agency',\n",
       " 'aggressive',\n",
       " 'agree',\n",
       " 'agreed',\n",
       " 'agreement',\n",
       " 'ah',\n",
       " 'ahead',\n",
       " 'aid',\n",
       " 'aircraft',\n",
       " 'airline',\n",
       " 'aka',\n",
       " 'alert',\n",
       " 'algos',\n",
       " 'alibaba',\n",
       " 'alive',\n",
       " 'all-time',\n",
       " 'allow',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'alpha',\n",
       " 'alphabet',\n",
       " 'alright',\n",
       " 'alternative',\n",
       " 'amazing',\n",
       " 'amazon',\n",
       " 'america',\n",
       " 'american',\n",
       " 'ameritrade',\n",
       " 'amid',\n",
       " 'am|\\\\',\n",
       " 'analysis',\n",
       " 'analyst',\n",
       " 'and/or',\n",
       " 'animal',\n",
       " 'announce',\n",
       " 'announced',\n",
       " 'announcement',\n",
       " 'announces',\n",
       " 'announcing',\n",
       " 'annual',\n",
       " 'answer',\n",
       " 'antibody',\n",
       " 'anticipated',\n",
       " 'anticipation',\n",
       " 'anybody',\n",
       " 'anymore',\n",
       " 'anytime',\n",
       " 'anyways',\n",
       " 'app',\n",
       " 'apparently',\n",
       " 'appear',\n",
       " 'appears',\n",
       " 'apple',\n",
       " 'application',\n",
       " 'apply',\n",
       " 'appreciate',\n",
       " 'approach',\n",
       " 'approval',\n",
       " 'approved',\n",
       " 'approximately',\n",
       " 'apr',\n",
       " 'april',\n",
       " 'arabia',\n",
       " 'area',\n",
       " 'aren',\n",
       " 'argument',\n",
       " 'arm',\n",
       " 'art',\n",
       " 'article',\n",
       " 'asia',\n",
       " 'asia-pacific',\n",
       " 'asian',\n",
       " 'aside',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'ass',\n",
       " 'asset',\n",
       " 'asshole',\n",
       " 'assigned',\n",
       " 'associated',\n",
       " 'assume',\n",
       " 'assuming',\n",
       " 'assumption',\n",
       " 'atm',\n",
       " 'attack',\n",
       " 'attempt',\n",
       " 'attention',\n",
       " 'attractive',\n",
       " 'august',\n",
       " 'australia',\n",
       " 'autism',\n",
       " 'autist',\n",
       " 'autistic',\n",
       " 'autists',\n",
       " 'auto=webp',\n",
       " 'available',\n",
       " 'average',\n",
       " 'averaged',\n",
       " 'avg',\n",
       " 'avoid',\n",
       " 'aware',\n",
       " 'away',\n",
       " 'aws',\n",
       " 'azure',\n",
       " 'b',\n",
       " 'baby',\n",
       " 'backed',\n",
       " 'background',\n",
       " 'bad',\n",
       " 'bae',\n",
       " 'bag',\n",
       " 'bailout',\n",
       " 'balance',\n",
       " 'ball',\n",
       " 'ban',\n",
       " 'bank',\n",
       " 'banking',\n",
       " 'bankrupt',\n",
       " 'bankruptcy',\n",
       " 'banned',\n",
       " 'bar',\n",
       " 'barclays',\n",
       " 'barely',\n",
       " 'barrel',\n",
       " 'base',\n",
       " 'based',\n",
       " 'basic',\n",
       " 'basically',\n",
       " 'basis',\n",
       " 'bat',\n",
       " 'battery',\n",
       " 'battle',\n",
       " 'bb_20_2',\n",
       " 'bear',\n",
       " 'bearish',\n",
       " 'beat',\n",
       " 'beaten',\n",
       " 'beating',\n",
       " 'beautiful',\n",
       " 'becky',\n",
       " 'bed',\n",
       " 'beer',\n",
       " 'began',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'begun',\n",
       " 'behavior',\n",
       " 'belief',\n",
       " 'believe',\n",
       " 'bell',\n",
       " 'benchmark',\n",
       " 'benefit',\n",
       " 'bernie',\n",
       " 'bet',\n",
       " 'better',\n",
       " 'betting',\n",
       " 'bezos',\n",
       " 'bias',\n",
       " 'bid',\n",
       " 'biden',\n",
       " 'bigger',\n",
       " 'biggest',\n",
       " 'bigly',\n",
       " 'bike',\n",
       " 'billion',\n",
       " 'biotech',\n",
       " 'bitch',\n",
       " 'bitcoin',\n",
       " 'black',\n",
       " 'blah',\n",
       " 'blame',\n",
       " 'blew',\n",
       " 'bln',\n",
       " 'block',\n",
       " 'blood',\n",
       " 'bloomberg',\n",
       " 'blow',\n",
       " 'board',\n",
       " 'boat',\n",
       " 'body',\n",
       " 'boeing',\n",
       " 'bofa/merrill',\n",
       " 'bois',\n",
       " 'bond',\n",
       " 'bonus',\n",
       " 'book',\n",
       " 'boomer',\n",
       " 'boost',\n",
       " 'bored',\n",
       " 'boring',\n",
       " 'borrow',\n",
       " 'borrowing',\n",
       " 'bot',\n",
       " 'bought',\n",
       " 'bounce',\n",
       " 'bound',\n",
       " 'boy',\n",
       " 'boyfriend',\n",
       " 'brain',\n",
       " 'brand',\n",
       " 'branson',\n",
       " 'break',\n",
       " 'breakdown',\n",
       " 'breaker',\n",
       " 'breaking',\n",
       " 'breakout',\n",
       " 'brexit',\n",
       " 'briefing.com',\n",
       " 'bring',\n",
       " 'bringing',\n",
       " 'brings',\n",
       " 'british',\n",
       " 'broad',\n",
       " 'broader',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'broker',\n",
       " 'brokerage',\n",
       " 'brother',\n",
       " 'brought',\n",
       " 'btw',\n",
       " 'bubble',\n",
       " 'buck',\n",
       " 'budget',\n",
       " 'buffet',\n",
       " 'buffett',\n",
       " 'build',\n",
       " 'building',\n",
       " 'built',\n",
       " 'bull',\n",
       " 'bullish',\n",
       " 'bullshit',\n",
       " 'bump',\n",
       " 'bunch',\n",
       " 'burger',\n",
       " 'burn',\n",
       " 'burned',\n",
       " 'burning',\n",
       " 'business',\n",
       " 'bust',\n",
       " 'busy',\n",
       " 'button',\n",
       " 'buy',\n",
       " 'buyback',\n",
       " 'buyer',\n",
       " 'buying',\n",
       " 'buyout',\n",
       " 'ca',\n",
       " 'calculation',\n",
       " 'calendar',\n",
       " 'california',\n",
       " 'called',\n",
       " 'calling',\n",
       " 'came',\n",
       " 'camera',\n",
       " 'canada',\n",
       " 'canadian',\n",
       " 'cancel',\n",
       " 'canceled',\n",
       " 'cancelled',\n",
       " 'cancer',\n",
       " 'candidate',\n",
       " 'candle',\n",
       " 'cannabis',\n",
       " 'cap',\n",
       " 'capacity',\n",
       " 'capital',\n",
       " 'capture',\n",
       " 'card',\n",
       " 'care',\n",
       " 'careful',\n",
       " 'carry',\n",
       " 'case',\n",
       " 'casino',\n",
       " 'catalyst',\n",
       " 'catch',\n",
       " 'category',\n",
       " 'caught',\n",
       " 'cause',\n",
       " 'caused',\n",
       " 'causing',\n",
       " 'cell',\n",
       " 'cent',\n",
       " 'center',\n",
       " 'central',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'chad',\n",
       " 'chain',\n",
       " 'chair',\n",
       " 'chairman',\n",
       " 'challenge',\n",
       " 'chance',\n",
       " 'change',\n",
       " 'changed',\n",
       " 'changing',\n",
       " 'channel',\n",
       " 'charge',\n",
       " 'chart',\n",
       " 'charter',\n",
       " 'chase',\n",
       " 'cheap',\n",
       " 'cheaper',\n",
       " 'check',\n",
       " 'checked',\n",
       " 'checking',\n",
       " 'cheese',\n",
       " 'chicago',\n",
       " 'chicken',\n",
       " 'chief',\n",
       " 'child',\n",
       " 'china',\n",
       " 'chinese',\n",
       " 'chip',\n",
       " 'choice',\n",
       " 'choose',\n",
       " 'christmas',\n",
       " 'circuit',\n",
       " 'cisco',\n",
       " 'citigroup',\n",
       " 'citizen',\n",
       " 'city',\n",
       " 'claim',\n",
       " 'class',\n",
       " 'classic',\n",
       " 'clean',\n",
       " 'clear',\n",
       " 'clearly',\n",
       " 'click',\n",
       " 'client',\n",
       " 'climb',\n",
       " 'climbing',\n",
       " 'clinical',\n",
       " 'close',\n",
       " 'closed',\n",
       " 'closely',\n",
       " 'closer',\n",
       " 'closing',\n",
       " 'closure',\n",
       " 'cloud',\n",
       " 'clue',\n",
       " 'cnbc',\n",
       " 'co.',\n",
       " 'cock',\n",
       " 'code',\n",
       " 'coffee',\n",
       " 'coin',\n",
       " 'collapse',\n",
       " 'collateral',\n",
       " 'collect',\n",
       " 'college',\n",
       " 'color',\n",
       " 'combination',\n",
       " 'combined',\n",
       " 'come',\n",
       " 'coming',\n",
       " 'comment',\n",
       " 'commercial',\n",
       " 'commission',\n",
       " 'committee',\n",
       " 'commodity',\n",
       " 'common',\n",
       " 'communication',\n",
       " 'community',\n",
       " 'company',\n",
       " 'comparable',\n",
       " 'compare',\n",
       " 'compared',\n",
       " 'comparison',\n",
       " 'competition',\n",
       " 'competitive',\n",
       " 'competitor',\n",
       " 'complete',\n",
       " 'completed',\n",
       " 'completely',\n",
       " 'complex',\n",
       " 'complicated',\n",
       " 'component',\n",
       " 'composite',\n",
       " 'computer',\n",
       " 'computing',\n",
       " 'concept',\n",
       " 'concern',\n",
       " 'concerned',\n",
       " 'conclusion',\n",
       " 'condition',\n",
       " 'condor',\n",
       " 'conference',\n",
       " 'confidence',\n",
       " 'confident',\n",
       " 'confirm',\n",
       " 'confirmation',\n",
       " 'confirmed',\n",
       " 'confused',\n",
       " 'congress',\n",
       " 'consensus',\n",
       " 'conservative',\n",
       " 'consider',\n",
       " 'considered',\n",
       " 'considering',\n",
       " 'consistent',\n",
       " 'consistently',\n",
       " 'console',\n",
       " 'constant',\n",
       " 'constantly',\n",
       " 'construction',\n",
       " 'consumer',\n",
       " 'consumption',\n",
       " 'contact',\n",
       " 'contango',\n",
       " 'content',\n",
       " 'continue',\n",
       " 'continued',\n",
       " 'continues',\n",
       " 'continuing',\n",
       " 'contract',\n",
       " 'control',\n",
       " 'convinced',\n",
       " 'cool',\n",
       " 'copper',\n",
       " 'corn',\n",
       " 'corona',\n",
       " 'coronavirus',\n",
       " 'corp',\n",
       " 'corp.',\n",
       " 'corporate',\n",
       " 'corporation',\n",
       " 'correct',\n",
       " 'correction',\n",
       " 'correlation',\n",
       " 'cost',\n",
       " 'costco',\n",
       " 'couldn',\n",
       " 'count',\n",
       " 'country',\n",
       " 'couple',\n",
       " 'course',\n",
       " 'court',\n",
       " 'courtesy',\n",
       " 'covenant',\n",
       " 'cover',\n",
       " 'coverage',\n",
       " 'covered',\n",
       " 'covid',\n",
       " 'covid-19',\n",
       " 'covid19',\n",
       " 'cpi',\n",
       " 'cpu',\n",
       " 'cramer',\n",
       " 'crap',\n",
       " 'crash',\n",
       " 'crashed',\n",
       " 'crashing',\n",
       " 'crazy',\n",
       " 'create',\n",
       " 'created',\n",
       " 'creating',\n",
       " 'credit',\n",
       " 'crisis',\n",
       " 'critical',\n",
       " 'cross',\n",
       " 'crude',\n",
       " 'cruise',\n",
       " 'crush',\n",
       " 'crushed',\n",
       " 'cuck',\n",
       " 'cup',\n",
       " 'cure',\n",
       " 'curious',\n",
       " 'currency',\n",
       " 'current',\n",
       " 'currently',\n",
       " 'curve',\n",
       " 'customer',\n",
       " 'cut',\n",
       " 'cutting',\n",
       " 'cycle',\n",
       " 'dad',\n",
       " 'daddy',\n",
       " 'daily',\n",
       " 'damage',\n",
       " 'damn',\n",
       " 'dark',\n",
       " 'data',\n",
       " 'date',\n",
       " 'dated',\n",
       " 'day',\n",
       " 'dead',\n",
       " 'deal',\n",
       " 'dealer',\n",
       " 'death',\n",
       " 'debit',\n",
       " 'debt',\n",
       " 'dec',\n",
       " 'decade',\n",
       " 'decay',\n",
       " 'december',\n",
       " 'decent',\n",
       " 'decide',\n",
       " 'decided',\n",
       " 'decision',\n",
       " 'decline',\n",
       " 'declined',\n",
       " 'declining',\n",
       " 'decrease',\n",
       " 'decreased',\n",
       " 'decreasing',\n",
       " 'deep',\n",
       " 'deeper',\n",
       " 'default',\n",
       " 'defense',\n",
       " 'deficit',\n",
       " 'definitely',\n",
       " 'deflation',\n",
       " 'degenerate',\n",
       " 'degree',\n",
       " 'delay',\n",
       " 'delayed',\n",
       " 'deleted',\n",
       " 'deliver',\n",
       " 'delivered',\n",
       " 'delivery',\n",
       " 'delta',\n",
       " 'demand',\n",
       " 'democrat',\n",
       " 'department',\n",
       " 'dependent',\n",
       " 'depending',\n",
       " 'deposit',\n",
       " 'depot',\n",
       " 'depression',\n",
       " 'derivative',\n",
       " 'design',\n",
       " 'designed',\n",
       " 'despite',\n",
       " 'determine',\n",
       " 'deutsche',\n",
       " 'develop',\n",
       " 'developed',\n",
       " 'developer',\n",
       " 'developing',\n",
       " 'development',\n",
       " 'device',\n",
       " 'diamond',\n",
       " 'dick',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'didnt',\n",
       " 'die',\n",
       " 'died',\n",
       " 'difference',\n",
       " 'different',\n",
       " 'difficult',\n",
       " 'digit',\n",
       " 'digital',\n",
       " 'dildo',\n",
       " 'diligence',\n",
       " 'dip',\n",
       " 'dipped',\n",
       " 'direct',\n",
       " 'direction',\n",
       " 'directly',\n",
       " 'director',\n",
       " 'dirt',\n",
       " 'disaster',\n",
       " 'disclaimer',\n",
       " 'disclosed',\n",
       " 'disclosure',\n",
       " 'discount',\n",
       " 'discovered',\n",
       " 'discus',\n",
       " 'discussed',\n",
       " 'discussion',\n",
       " 'disease',\n",
       " 'disney',\n",
       " 'disney+',\n",
       " 'disruption',\n",
       " 'distancing',\n",
       " 'distribution',\n",
       " 'dive',\n",
       " 'dividend',\n",
       " 'division',\n",
       " 'djia',\n",
       " 'doctor',\n",
       " 'document',\n",
       " 'doe',\n",
       " 'doesn',\n",
       " 'doesnt',\n",
       " 'dog',\n",
       " 'doing',\n",
       " 'dollar',\n",
       " 'domestic',\n",
       " 'don',\n",
       " 'donald',\n",
       " 'dont',\n",
       " 'double',\n",
       " 'doubled',\n",
       " 'doubling',\n",
       " 'doubt',\n",
       " 'downgrade',\n",
       " 'downgraded',\n",
       " 'downside',\n",
       " 'downtrend',\n",
       " 'downturn',\n",
       " 'downward',\n",
       " 'dozen',\n",
       " 'dr',\n",
       " 'dr**',\n",
       " 'dr.',\n",
       " 'dramatically',\n",
       " 'draw',\n",
       " 'dream',\n",
       " 'drifted',\n",
       " 'drink',\n",
       " 'drive',\n",
       " 'driven',\n",
       " 'driver',\n",
       " 'driving',\n",
       " 'drop',\n",
       " 'dropped',\n",
       " 'dropping',\n",
       " 'drug',\n",
       " 'dude',\n",
       " 'dumb',\n",
       " 'dumbass',\n",
       " 'dump',\n",
       " 'dying',\n",
       " 'earlier',\n",
       " 'early',\n",
       " 'earned',\n",
       " 'earning',\n",
       " 'earnings',\n",
       " 'earth',\n",
       " 'easier',\n",
       " 'easily',\n",
       " 'easy',\n",
       " 'eating',\n",
       " 'ebitda',\n",
       " 'economic',\n",
       " 'economics',\n",
       " 'economist',\n",
       " 'economy',\n",
       " 'edge',\n",
       " 'education',\n",
       " 'effect',\n",
       " 'effective',\n",
       " 'effectively',\n",
       " 'effort',\n",
       " 'election',\n",
       " 'electric',\n",
       " 'elon',\n",
       " 'em',\n",
       " 'email',\n",
       " 'emergency',\n",
       " 'employee',\n",
       " 'employment',\n",
       " 'end',\n",
       " 'ended',\n",
       " 'ending',\n",
       " 'energy',\n",
       " 'engineer',\n",
       " 'enjoy',\n",
       " 'ensure',\n",
       " 'enter',\n",
       " 'entered',\n",
       " 'entering',\n",
       " 'enterprise',\n",
       " 'entertainment',\n",
       " 'entire',\n",
       " 'entirely',\n",
       " 'entry',\n",
       " 'environment',\n",
       " 'epidemic',\n",
       " 'eps',\n",
       " 'equal',\n",
       " 'equipment',\n",
       " 'equity',\n",
       " 'equivalent',\n",
       " 'er',\n",
       " 'error',\n",
       " 'especially',\n",
       " 'essential',\n",
       " 'essentially',\n",
       " 'est',\n",
       " 'established',\n",
       " 'estate',\n",
       " 'estimate',\n",
       " 'estimated',\n",
       " 'etf',\n",
       " 'eu',\n",
       " 'europe',\n",
       " 'european',\n",
       " 'eurozone',\n",
       " 'event',\n",
       " 'eventually',\n",
       " 'everybody',\n",
       " 'everyday',\n",
       " 'evidence',\n",
       " 'exact',\n",
       " 'exactly',\n",
       " 'example',\n",
       " 'excellent',\n",
       " 'exchange',\n",
       " 'excited',\n",
       " 'excluding',\n",
       " 'execute',\n",
       " 'executive',\n",
       " 'exercise',\n",
       " 'exercised',\n",
       " 'exist',\n",
       " 'existing',\n",
       " 'exit',\n",
       " 'expand',\n",
       " 'expanding',\n",
       " 'expansion',\n",
       " 'expect',\n",
       " 'expectation',\n",
       " 'expected',\n",
       " 'expecting',\n",
       " 'expects',\n",
       " 'expense',\n",
       " 'expensive',\n",
       " 'experience',\n",
       " 'experienced',\n",
       " 'expert',\n",
       " 'expiration',\n",
       " 'expire',\n",
       " 'expired',\n",
       " 'expires',\n",
       " 'expiring',\n",
       " 'expiry',\n",
       " 'explain',\n",
       " 'explained',\n",
       " 'explanation',\n",
       " 'export',\n",
       " 'exposed',\n",
       " 'exposure',\n",
       " 'express',\n",
       " 'extended',\n",
       " 'extra',\n",
       " 'extreme',\n",
       " 'extremely',\n",
       " 'face',\n",
       " 'facebook',\n",
       " 'facility',\n",
       " 'facing',\n",
       " 'fact',\n",
       " 'factor',\n",
       " 'factory',\n",
       " 'fail',\n",
       " 'failed',\n",
       " 'failing',\n",
       " 'failure',\n",
       " 'fair',\n",
       " 'fairly',\n",
       " 'faith',\n",
       " 'fake',\n",
       " 'fall',\n",
       " 'fallen',\n",
       " 'falling',\n",
       " 'false',\n",
       " 'familiar',\n",
       " 'family',\n",
       " 'fan',\n",
       " 'far',\n",
       " 'fargo',\n",
       " 'fashion',\n",
       " 'faster',\n",
       " 'fauci',\n",
       " 'favor',\n",
       " 'favorite',\n",
       " 'fd',\n",
       " 'fda',\n",
       " 'fear',\n",
       " 'feature',\n",
       " 'feb',\n",
       " 'february',\n",
       " 'fed',\n",
       " 'federal',\n",
       " 'fedex',\n",
       " 'fee',\n",
       " 'feed',\n",
       " 'feedback',\n",
       " 'feel',\n",
       " 'feeling',\n",
       " 'fell',\n",
       " 'fellow',\n",
       " 'felt',\n",
       " 'fewer',\n",
       " 'fidelity',\n",
       " 'field',\n",
       " 'fight',\n",
       " 'figure',\n",
       " 'figured',\n",
       " 'file',\n",
       " 'filed',\n",
       " 'filing',\n",
       " 'filled',\n",
       " 'filler',\n",
       " 'final',\n",
       " 'finally',\n",
       " 'finance',\n",
       " 'financial',\n",
       " 'financials',\n",
       " 'financing',\n",
       " 'finding',\n",
       " 'fine',\n",
       " 'finger',\n",
       " 'finish',\n",
       " 'finished',\n",
       " 'firm',\n",
       " 'fiscal',\n",
       " 'fitness',\n",
       " 'fixed',\n",
       " 'flag',\n",
       " 'flair',\n",
       " 'flash',\n",
       " 'fleet',\n",
       " 'flight',\n",
       " 'flip',\n",
       " 'float',\n",
       " 'floor',\n",
       " 'florida',\n",
       " 'flow',\n",
       " 'flu',\n",
       " 'flying',\n",
       " 'focus',\n",
       " 'focused',\n",
       " 'folk',\n",
       " 'follow',\n",
       " 'followed',\n",
       " 'following',\n",
       " 'fomo',\n",
       " 'food',\n",
       " 'fool',\n",
       " 'foot',\n",
       " 'force',\n",
       " 'forced',\n",
       " 'forecast',\n",
       " 'foreign',\n",
       " 'forever',\n",
       " 'forget',\n",
       " 'forgot',\n",
       " 'format=pjpg',\n",
       " 'format=png',\n",
       " 'forum',\n",
       " 'forward',\n",
       " 'fourth',\n",
       " 'france',\n",
       " 'fraud',\n",
       " 'fresh',\n",
       " 'friday',\n",
       " 'friend',\n",
       " 'ftse',\n",
       " 'fuck',\n",
       " 'fucked',\n",
       " 'fucker',\n",
       " 'fuckin',\n",
       " 'fucking',\n",
       " 'fuel',\n",
       " 'fuk',\n",
       " 'full-year',\n",
       " 'fully',\n",
       " 'function',\n",
       " 'fund',\n",
       " 'fundamental',\n",
       " 'funding',\n",
       " 'furthermore',\n",
       " 'future',\n",
       " 'fy',\n",
       " 'fy19',\n",
       " 'fy20',\n",
       " 'gain',\n",
       " 'gained',\n",
       " 'gaining',\n",
       " 'gainz',\n",
       " 'galactic',\n",
       " 'gamble',\n",
       " 'gambler',\n",
       " 'gambling',\n",
       " 'game',\n",
       " 'gamestop',\n",
       " 'gaming',\n",
       " 'gamma',\n",
       " 'gang',\n",
       " 'gap',\n",
       " 'garbage',\n",
       " 'gas',\n",
       " 'gate',\n",
       " 'gave',\n",
       " 'gay',\n",
       " 'general',\n",
       " 'generally',\n",
       " 'generate',\n",
       " 'generated',\n",
       " 'generation',\n",
       " 'genius',\n",
       " 'german',\n",
       " 'germany',\n",
       " 'getting',\n",
       " 'gex',\n",
       " 'giant',\n",
       " 'gilead',\n",
       " 'girl',\n",
       " 'girlfriend',\n",
       " 'given',\n",
       " 'giving',\n",
       " 'glass',\n",
       " 'gld',\n",
       " 'glitch',\n",
       " 'global',\n",
       " 'globally',\n",
       " 'goal',\n",
       " 'god',\n",
       " 'goddamn',\n",
       " 'going',\n",
       " 'golden',\n",
       " 'goldman',\n",
       " 'gon',\n",
       " 'gone',\n",
       " 'good',\n",
       " 'google',\n",
       " 'got',\n",
       " 'gotten',\n",
       " 'gov',\n",
       " 'government',\n",
       " 'governor',\n",
       " 'grab',\n",
       " 'grade',\n",
       " 'grand',\n",
       " 'granted',\n",
       " 'graph',\n",
       " 'great',\n",
       " 'greater',\n",
       " 'greatest',\n",
       " 'greedy',\n",
       " 'greek',\n",
       " 'green',\n",
       " 'grew',\n",
       " 'grocery',\n",
       " 'gross',\n",
       " 'ground',\n",
       " 'group',\n",
       " 'growing',\n",
       " 'grown',\n",
       " 'growth',\n",
       " 'guarantee',\n",
       " 'guaranteed',\n",
       " 'guess',\n",
       " 'guh',\n",
       " 'guidance',\n",
       " 'guide',\n",
       " 'gun',\n",
       " 'guy',\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [####################] 98.6%\n"
     ]
    }
   ],
   "source": [
    "threshhold=.05\n",
    "lt = LemmaTokenizer()\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def calculateData(post):\n",
    "    #print(post)\n",
    "    data=post[\"data\"]\n",
    "    thesesymbols=post[\"symbols\"]\n",
    "    text = data[\"title\"]+\" \"+data[\"selftext\"]\n",
    "    texttokens=lt(text)\n",
    "    #print(text,texttokens)\n",
    "    #print(\"Symbol:\",thesesymbols)\n",
    "    wordvector=[]\n",
    "    for word in vocab_list:\n",
    "        wordvector.append(texttokens.count(word))\n",
    "    returnarray=[]\n",
    "    for symbolmap in thesesymbols:\n",
    "        symbol=list(symbolmap.keys())[0]\n",
    "        try:\n",
    "        #if True:\n",
    "            \n",
    "                #if word in texttokens:\n",
    "                    #print(word)\n",
    "                #    wordvector.append(1)\n",
    "                #else:\n",
    "                #    wordvector.append(0)\n",
    "                #locword = text.find(word)\n",
    "                #distance=0\n",
    "                #if locword>-1:\n",
    "                #    distance=abs(text.find(symbolmap[symbol])-locword)\n",
    "                #    print(symbol,word,distance)\n",
    "                #wordvector.append(distance)\n",
    "            #print(symbol,wordvector)\n",
    "            posttime=[0,0,0,0]\n",
    "            start=ET.localize(datetime.datetime.fromtimestamp(data[\"created_utc\"]))\n",
    "            if start.hour>=21:\n",
    "                posttime[0]=1\n",
    "            elif start.hour < 5:\n",
    "                posttime[0]=1\n",
    "            elif start.hour < 9:\n",
    "                posttime[1]=1\n",
    "            elif start.hour < 16:\n",
    "                posttime[2]=1\n",
    "            else:\n",
    "                posttime[3]=1\n",
    "            if start.hour>=9:\n",
    "                start=start+datetime.timedelta(days=1)\n",
    "            start=start.replace(hour=9,minute=0,second=0,microsecond=0).date()\n",
    "            end=start+dt\n",
    "            startprice=getstockprice(symbol,start)\n",
    "            endprice=getstockprice(symbol,end)\n",
    "            #print(start,end,history)\n",
    "            delta=(endprice-startprice)/startprice\n",
    "            if delta<=-1*(threshhold):\n",
    "                result=1\n",
    "            elif delta>=threshhold:\n",
    "                result=2\n",
    "                #print(symbol,delta,result,wordvector)\n",
    "            else:\n",
    "                result=0\n",
    "            returnarray.append([result]+posttime+wordvector)\n",
    "        except Exception as err:\n",
    "            print(\"Error with\",symbol,\", skipping this one:\",err)\n",
    "    return returnarray\n",
    "\n",
    "\n",
    "def calculateVectors(posts):\n",
    "    vector = []\n",
    "    i=0\n",
    "    for post in posts:\n",
    "        #try:\n",
    "        if True:\n",
    "           response=calculateData(post)\n",
    "           for row in response:\n",
    "                vector.append(row)\n",
    "        #except Exception as err:\n",
    "        #    print(\"Error\",err)\n",
    "        #    pass\n",
    "        i+=1\n",
    "        if(round(i/100,0)==i/100):\n",
    "            update_progress(i / len(posts))\n",
    "    vector=np.array(vector).astype('float32')\n",
    "    return vector\n",
    "\n",
    "training_vector = calculateVectors(training_posts)\n",
    "test_vector = calculateVectors(test_posts)\n",
    "val_vector = calculateVectors(val_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Output</th>\n",
       "      <th>21-4</th>\n",
       "      <th>5-8</th>\n",
       "      <th>9-15</th>\n",
       "      <th>16-20</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accept</th>\n",
       "      <th>...</th>\n",
       "      <th>yolos</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yoy</th>\n",
       "      <th>yr/yr</th>\n",
       "      <th>ytd</th>\n",
       "      <th>zero</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69700</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69701</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69702</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69703</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69704</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69705 rows × 2505 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Output  21-4  5-8  9-15  16-20  ability  able  absolute  absolutely  \\\n",
       "0         1.0   1.0  0.0   0.0    0.0      0.0   0.0       0.0         0.0   \n",
       "1         1.0   1.0  0.0   0.0    0.0      0.0   0.0       0.0         0.0   \n",
       "2         0.0   1.0  0.0   0.0    0.0      0.0   0.0       0.0         0.0   \n",
       "3         0.0   1.0  0.0   0.0    0.0      0.0   0.0       0.0         0.0   \n",
       "4         2.0   0.0  0.0   0.0    1.0      0.0   0.0       0.0         0.0   \n",
       "...       ...   ...  ...   ...    ...      ...   ...       ...         ...   \n",
       "69700     1.0   0.0  0.0   1.0    0.0      2.0   2.0       0.0         0.0   \n",
       "69701     1.0   0.0  0.0   1.0    0.0      2.0   2.0       0.0         0.0   \n",
       "69702     1.0   0.0  0.0   1.0    0.0      2.0   2.0       0.0         0.0   \n",
       "69703     0.0   0.0  0.0   1.0    0.0      2.0   2.0       0.0         0.0   \n",
       "69704     1.0   0.0  0.0   1.0    0.0      2.0   2.0       0.0         0.0   \n",
       "\n",
       "       accept  ...  yolos  york  young  youtube  yoy  yr/yr  ytd  zero  zone  \\\n",
       "0         0.0  ...    0.0   0.0    0.0      0.0  0.0    0.0  0.0   0.0   0.0   \n",
       "1         0.0  ...    0.0   0.0    0.0      0.0  0.0    0.0  0.0   0.0   0.0   \n",
       "2         0.0  ...    0.0   0.0    0.0      0.0  0.0    0.0  0.0   0.0   0.0   \n",
       "3         0.0  ...    0.0   0.0    0.0      0.0  0.0    0.0  0.0   0.0   0.0   \n",
       "4         0.0  ...    0.0   0.0    0.0      0.0  0.0    0.0  0.0   0.0   0.0   \n",
       "...       ...  ...    ...   ...    ...      ...  ...    ...  ...   ...   ...   \n",
       "69700     0.0  ...    0.0   0.0    0.0      0.0  0.0    0.0  0.0   0.0   0.0   \n",
       "69701     0.0  ...    0.0   0.0    0.0      0.0  0.0    0.0  0.0   0.0   0.0   \n",
       "69702     0.0  ...    0.0   0.0    0.0      0.0  0.0    0.0  0.0   0.0   0.0   \n",
       "69703     0.0  ...    0.0   0.0    0.0      0.0  0.0    0.0  0.0   0.0   0.0   \n",
       "69704     0.0  ...    0.0   0.0    0.0      0.0  0.0    0.0  0.0   0.0   0.0   \n",
       "\n",
       "       zoom  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  \n",
       "...     ...  \n",
       "69700   0.0  \n",
       "69701   0.0  \n",
       "69702   0.0  \n",
       "69703   0.0  \n",
       "69704   0.0  \n",
       "\n",
       "[69705 rows x 2505 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(training_vector, columns=[\"Output\"]+[\"21-4\",\"5-8\",\"9-15\",\"16-20\"]+vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_vector[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.8 ms, sys: 0 ns, total: 13.8 ms\n",
      "Wall time: 13.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import struct\n",
    "import io\n",
    "import boto3\n",
    "\n",
    "prefix='wsb-xgboost'\n",
    "region = boto3.Session().region_name\n",
    " \n",
    "def to_libsvm(f, labels, values):\n",
    "     f.write(bytes('\\n'.join(\n",
    "         ['{} {}'.format(label, ' '.join(['{}:{}'.format(i + 1, el) for i, el in enumerate(vec)])) for label, vec in\n",
    "          zip(labels, values)]), 'utf-8'))\n",
    "     return f\n",
    "\n",
    "\n",
    "def write_to_s3(fobj, bucket, key):\n",
    "    return boto3.Session(region_name=region).resource('s3').Bucket(bucket).Object(key).upload_fileobj(fobj)\n",
    "\n",
    "def upload_to_s3(partition_name, partition):\n",
    "    labels = [t.tolist() for t in partition[:,0]]\n",
    "    vectors = [t.tolist() for t in partition[:,1:]]\n",
    "    num_partition = 5                                 # partition file into 5 parts\n",
    "    partition_bound = int(len(labels)/num_partition)\n",
    "    for i in range(num_partition):\n",
    "        f = io.BytesIO()\n",
    "        to_libsvm(f, labels[i*partition_bound:(i+1)*partition_bound], vectors[i*partition_bound:(i+1)*partition_bound])\n",
    "        f.seek(0)\n",
    "        key = \"{}/{}/examples{}\".format(prefix,partition_name,str(i))\n",
    "        url = 's3n://{}/{}'.format(bucket, key)\n",
    "        print('Writing to {}'.format(url))\n",
    "        write_to_s3(f, bucket, key)\n",
    "        print('Done writing to {}'.format(url))\n",
    "\n",
    "def download_from_s3(partition_name, number, filename):\n",
    "    key = \"{}/{}/examples{}\".format(prefix,partition_name, number)\n",
    "    url = 's3n://{}/{}'.format(bucket, key)\n",
    "    print('Reading from {}'.format(url))\n",
    "    s3 = boto3.resource('s3', region_name = region)\n",
    "    s3.Bucket(bucket).download_file(key, filename)\n",
    "    #try:\n",
    "    #    s3.Bucket(bucket).download_file(key, 'mnist.local.test')\n",
    "    #except botocore.exceptions.ClientError as e:\n",
    "    #    if e.response['Error']['Code'] == \"404\":\n",
    "    #        print('The object does not exist at {}.'.format(url))\n",
    "    #    else:\n",
    "    #        raise        \n",
    "        \n",
    "def convert_data():\n",
    "    partitions = [('train', training_vector), ('validation', val_vector), ('test', test_vector)]\n",
    "    for partition_name, partition in partitions:\n",
    "        print('{}: {} {}'.format(partition_name, partition[:,0].shape, partition[:,1:].shape))\n",
    "        upload_to_s3(partition_name, partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7805, 2504)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_vector[:,1:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (69705,) (69705, 2504)\n",
      "Writing to s3n://sagemaker-us-east-1-011113936377/wsb-xgboost/train/examples0\n",
      "Done writing to s3n://sagemaker-us-east-1-011113936377/wsb-xgboost/train/examples0\n",
      "Writing to s3n://sagemaker-us-east-1-011113936377/wsb-xgboost/train/examples1\n",
      "Done writing to s3n://sagemaker-us-east-1-011113936377/wsb-xgboost/train/examples1\n",
      "Writing to s3n://sagemaker-us-east-1-011113936377/wsb-xgboost/train/examples2\n",
      "Done writing to s3n://sagemaker-us-east-1-011113936377/wsb-xgboost/train/examples2\n",
      "Writing to s3n://sagemaker-us-east-1-011113936377/wsb-xgboost/train/examples3\n",
      "Done writing to s3n://sagemaker-us-east-1-011113936377/wsb-xgboost/train/examples3\n",
      "Writing to s3n://sagemaker-us-east-1-011113936377/wsb-xgboost/train/examples4\n",
      "Done writing to s3n://sagemaker-us-east-1-011113936377/wsb-xgboost/train/examples4\n",
      "validation: (7805,) (7805, 2504)\n",
      "Writing to s3n://sagemaker-us-east-1-011113936377/wsb-xgboost/validation/examples0\n",
      "Done writing to s3n://sagemaker-us-east-1-011113936377/wsb-xgboost/validation/examples0\n",
      "Writing to s3n://sagemaker-us-east-1-011113936377/wsb-xgboost/validation/examples1\n",
      "Done writing to s3n://sagemaker-us-east-1-011113936377/wsb-xgboost/validation/examples1\n",
      "Writing to s3n://sagemaker-us-east-1-011113936377/wsb-xgboost/validation/examples2\n",
      "Done writing to s3n://sagemaker-us-east-1-011113936377/wsb-xgboost/validation/examples2\n",
      "Writing to s3n://sagemaker-us-east-1-011113936377/wsb-xgboost/validation/examples3\n",
      "Done writing to s3n://sagemaker-us-east-1-011113936377/wsb-xgboost/validation/examples3\n",
      "Writing to s3n://sagemaker-us-east-1-011113936377/wsb-xgboost/validation/examples4\n",
      "Done writing to s3n://sagemaker-us-east-1-011113936377/wsb-xgboost/validation/examples4\n",
      "test: (8480,) (8480, 2504)\n",
      "Writing to s3n://sagemaker-us-east-1-011113936377/wsb-xgboost/test/examples0\n",
      "Done writing to s3n://sagemaker-us-east-1-011113936377/wsb-xgboost/test/examples0\n",
      "Writing to s3n://sagemaker-us-east-1-011113936377/wsb-xgboost/test/examples1\n",
      "Done writing to s3n://sagemaker-us-east-1-011113936377/wsb-xgboost/test/examples1\n",
      "Writing to s3n://sagemaker-us-east-1-011113936377/wsb-xgboost/test/examples2\n",
      "Done writing to s3n://sagemaker-us-east-1-011113936377/wsb-xgboost/test/examples2\n",
      "Writing to s3n://sagemaker-us-east-1-011113936377/wsb-xgboost/test/examples3\n",
      "Done writing to s3n://sagemaker-us-east-1-011113936377/wsb-xgboost/test/examples3\n",
      "Writing to s3n://sagemaker-us-east-1-011113936377/wsb-xgboost/test/examples4\n",
      "Done writing to s3n://sagemaker-us-east-1-011113936377/wsb-xgboost/test/examples4\n",
      "CPU times: user 2min 38s, sys: 12.4 s, total: 2min 50s\n",
      "Wall time: 2min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "convert_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "WARNING:root:There is a more up to date SageMaker XGBoost image. To use the newer image, please set 'repo_version'='1.0-1'. For example:\n",
      "\tget_image_uri(region, 'xgboost', '1.0-1').\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "container = get_image_uri(region, 'xgboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_job_config = {\n",
    "    \"ParameterRanges\": {\n",
    "      \"CategoricalParameterRanges\": [],\n",
    "      \"ContinuousParameterRanges\": [\n",
    "        {\n",
    "          \"MaxValue\": \"1\",\n",
    "          \"MinValue\": \"0\",\n",
    "          \"Name\": \"eta\"\n",
    "        },\n",
    "        {\n",
    "          \"MaxValue\": \"2\",\n",
    "          \"MinValue\": \"0\",\n",
    "          \"Name\": \"alpha\"\n",
    "        },\n",
    "        {\n",
    "          \"MaxValue\": \"10\",\n",
    "          \"MinValue\": \"1\",\n",
    "          \"Name\": \"min_child_weight\"\n",
    "        }\n",
    "      ],\n",
    "      \"IntegerParameterRanges\": [\n",
    "        {\n",
    "          \"MaxValue\": \"10\",\n",
    "          \"MinValue\": \"1\",\n",
    "          \"Name\": \"max_depth\"\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    \"ResourceLimits\": {\n",
    "      \"MaxNumberOfTrainingJobs\": 20,\n",
    "      \"MaxParallelTrainingJobs\": 3\n",
    "    },\n",
    "    \"Strategy\": \"Bayesian\",\n",
    "    \"HyperParameterTuningJobObjective\": {\n",
    "      \"MetricName\": \"validation:merror\",\n",
    "      \"Type\": \"Minimize\"\n",
    "    }\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_definition = {\n",
    "    \"AlgorithmSpecification\": {\n",
    "      \"TrainingImage\": container,\n",
    "      \"TrainingInputMode\": \"File\"\n",
    "    },\n",
    "    \"InputDataConfig\": [\n",
    "        {\n",
    "            \"ChannelName\": \"train\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": bucket_path + \"/\"+ prefix+ '/train/',\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\" \n",
    "                }\n",
    "            },\n",
    "            \"ContentType\": \"libsvm\",\n",
    "            \"CompressionType\": \"None\"\n",
    "        },\n",
    "        {\n",
    "            \"ChannelName\": \"validation\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": bucket_path + \"/\"+ prefix+ '/validation/',\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                }\n",
    "            },\n",
    "            \"ContentType\": \"libsvm\",\n",
    "            \"CompressionType\": \"None\"\n",
    "        }\n",
    "    ],\n",
    "    \"OutputDataConfig\": {\n",
    "      \"S3OutputPath\": \"s3://{}/{}/xgboost\".format(bucket,prefix)\n",
    "    },\n",
    "    \"ResourceConfig\": {\n",
    "        \"InstanceCount\": 2,   \n",
    "        \"InstanceType\": \"ml.m4.10xlarge\",\n",
    "        \"VolumeSizeInGB\": 5\n",
    "    },\n",
    "    \"RoleArn\": role,\n",
    "    \"StaticHyperParameters\": {\n",
    "      \"eval_metric\": \"merror\",\n",
    "      \"num_round\": \"100\",\n",
    "      \"objective\": \"multi:softmax\",\n",
    "      \"num_class\": \"3\",\n",
    "      \"rate_drop\": \"0.3\",\n",
    "      \"tweedie_variance_power\": \"1.4\"\n",
    "    },\n",
    "    \"StoppingCondition\": {\n",
    "      \"MaxRuntimeInSeconds\": 43200\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HyperParameterTuningJobArn': 'arn:aws:sagemaker:us-east-1:011113936377:hyper-parameter-tuning-job/mytuningjob2020-07-17-21-42-31',\n",
       " 'ResponseMetadata': {'RequestId': 'ba77d4ea-72b6-49e9-901e-4719adba2cb6',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'ba77d4ea-72b6-49e9-901e-4719adba2cb6',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '131',\n",
       "   'date': 'Fri, 17 Jul 2020 21:42:31 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "sm = boto3.Session(region_name=region).client('sagemaker')\n",
    "\n",
    "tuning_job_name = \"MyTuningJob\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "sm.create_hyper_parameter_tuning_job(HyperParameterTuningJobName = tuning_job_name,\n",
    "                                           HyperParameterTuningJobConfig = tuning_job_config,\n",
    "                                           TrainingJobDefinition = training_job_definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "bucket_path = 'https://s3-{}.amazonaws.com/{}'.format(region,bucket)\n",
    "\n",
    "#Ensure that the train and validation data folders generated above are reflected in the \"InputDataConfig\" parameter below.\n",
    "common_training_params = \\\n",
    "{\n",
    "    \"AlgorithmSpecification\": {\n",
    "        \"TrainingImage\": container,\n",
    "        \"TrainingInputMode\": \"File\"\n",
    "    },\n",
    "    \"RoleArn\": role,\n",
    "    \"OutputDataConfig\": {\n",
    "        \"S3OutputPath\": bucket_path + \"/\"+ prefix + \"/xgboost\"\n",
    "    },\n",
    "    \"ResourceConfig\": {\n",
    "        \"InstanceCount\": 1,   \n",
    "        \"InstanceType\": \"ml.m4.10xlarge\",\n",
    "        \"VolumeSizeInGB\": 5\n",
    "    },\n",
    "    \"HyperParameters\": {\n",
    "        \"max_depth\":\"5\",\n",
    "        \"eta\":\"0.2\",\n",
    "        \"gamma\":\"4\",\n",
    "        \"min_child_weight\":\"6\",\n",
    "        \"silent\":\"0\",\n",
    "        \"objective\": \"multi:softmax\",\n",
    "        \"num_class\": \"3\",\n",
    "        \"num_round\": \"30\"\n",
    "    },\n",
    "    \"StoppingCondition\": {\n",
    "        \"MaxRuntimeInSeconds\": 86400\n",
    "    },\n",
    "    \"InputDataConfig\": [\n",
    "        {\n",
    "            \"ChannelName\": \"train\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": bucket_path + \"/\"+ prefix+ '/train/',\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\" \n",
    "                }\n",
    "            },\n",
    "            \"ContentType\": \"libsvm\",\n",
    "            \"CompressionType\": \"None\"\n",
    "        },\n",
    "        {\n",
    "            \"ChannelName\": \"validation\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": bucket_path + \"/\"+ prefix+ '/validation/',\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                }\n",
    "            },\n",
    "            \"ContentType\": \"libsvm\",\n",
    "            \"CompressionType\": \"None\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job name is: wsb-xgboost-classification2020-07-17-20-18-44\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import copy\n",
    "\n",
    "#single machine job params\n",
    "single_machine_job_name = 'wsb-xgboost-classification' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(\"Job name is:\", single_machine_job_name)\n",
    "\n",
    "single_machine_job_params = copy.deepcopy(common_training_params)\n",
    "single_machine_job_params['TrainingJobName'] = single_machine_job_name\n",
    "single_machine_job_params['OutputDataConfig']['S3OutputPath'] = bucket_path + \"/\"+ prefix + \"/xgboost-single\"\n",
    "single_machine_job_params['ResourceConfig']['InstanceCount'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InProgress\n",
      "Training job ended with status: Completed\n",
      "CPU times: user 117 ms, sys: 8.07 ms, total: 125 ms\n",
      "Wall time: 4min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "\n",
    "sm.create_training_job(**single_machine_job_params)\n",
    "\n",
    "status = sm.describe_training_job(TrainingJobName=single_machine_job_name)['TrainingJobStatus']\n",
    "print(status)\n",
    "sm.get_waiter('training_job_completed_or_stopped').wait(TrainingJobName=single_machine_job_name)\n",
    "status = sm.describe_training_job(TrainingJobName=single_machine_job_name)['TrainingJobStatus']\n",
    "print(\"Training job ended with status: \" + status)\n",
    "if status == 'Failed':\n",
    "    message = sm.describe_training_job(TrainingJobName=single_machine_job_name)['FailureReason']\n",
    "    print('Training failed with the following error: {}'.format(message))\n",
    "    raise Exception('Training job failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wsb-xgboost-classification2020-07-15-21-28-25-mod\n",
      "https://s3-us-east-1.amazonaws.com/sagemaker-us-east-1-011113936377/wsb-xgboost/xgboost-single/wsb-xgboost-classification2020-07-15-21-28-25/output/model.tar.gz\n",
      "arn:aws:sagemaker:us-east-1:011113936377:model/wsb-xgboost-classification2020-07-15-21-28-25-mod\n",
      "CPU times: user 9.46 ms, sys: 32 µs, total: 9.49 ms\n",
      "Wall time: 407 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import boto3\n",
    "from time import gmtime, strftime\n",
    "\n",
    "model_name=single_machine_job_name + '-mod'\n",
    "print(model_name)\n",
    "\n",
    "info = sm.describe_training_job(TrainingJobName=single_machine_job_name)\n",
    "model_data = info['ModelArtifacts']['S3ModelArtifacts']\n",
    "print(model_data)\n",
    "\n",
    "primary_container = {\n",
    "    'Image': container,\n",
    "    'ModelDataUrl': model_data\n",
    "}\n",
    "\n",
    "create_model_response = sm.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    PrimaryContainer = primary_container)\n",
    "\n",
    "print(create_model_response['ModelArn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEMO-XGBoostEndpointConfig-2020-07-15-21-32-26\n",
      "Endpoint Config Arn: arn:aws:sagemaker:us-east-1:011113936377:endpoint-config/demo-xgboostendpointconfig-2020-07-15-21-32-26\n"
     ]
    }
   ],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "endpoint_config_name = 'DEMO-XGBoostEndpointConfig-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(endpoint_config_name)\n",
    "create_endpoint_config_response = sm.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_config_name,\n",
    "    ProductionVariants=[{\n",
    "        'InstanceType':'ml.m4.xlarge',\n",
    "        'InitialVariantWeight':1,\n",
    "        'InitialInstanceCount':1,\n",
    "        'ModelName':model_name,\n",
    "        'VariantName':'AllTraffic'}])\n",
    "\n",
    "print(\"Endpoint Config Arn: \" + create_endpoint_config_response['EndpointConfigArn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEMO-XGBoostEndpoint-2020-07-15-21-32-26\n",
      "arn:aws:sagemaker:us-east-1:011113936377:endpoint/demo-xgboostendpoint-2020-07-15-21-32-26\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: InService\n",
      "Arn: arn:aws:sagemaker:us-east-1:011113936377:endpoint/demo-xgboostendpoint-2020-07-15-21-32-26\n",
      "Status: InService\n",
      "CPU times: user 132 ms, sys: 7.99 ms, total: 140 ms\n",
      "Wall time: 8min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "\n",
    "endpoint_name = 'DEMO-XGBoostEndpoint-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(endpoint_name)\n",
    "create_endpoint_response = sm.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name)\n",
    "print(create_endpoint_response['EndpointArn'])\n",
    "\n",
    "resp = sm.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp['EndpointStatus']\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status=='Creating':\n",
    "    time.sleep(60)\n",
    "    resp = sm.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp['EndpointStatus']\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp['EndpointArn'])\n",
    "print(\"Status: \" + status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_client = boto3.client('runtime.sagemaker', region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from s3n://sagemaker-us-east-1-011113936377/wsb-xgboost/test/examples0\n"
     ]
    }
   ],
   "source": [
    "download_from_s3('test', 0, 'wsb.local.test') # reading the first part file within test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -1 wsb.local.test > wsb.single.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label is 0.0.\n",
      "CPU times: user 17.4 ms, sys: 4.07 ms, total: 21.5 ms\n",
      "Wall time: 184 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import json\n",
    "\n",
    "file_name = 'wsb.single.test' #customize to your test file 'mnist.single.test' if use the data above\n",
    "\n",
    "with open(file_name, 'r') as f:\n",
    "    payload = f.read()\n",
    "\n",
    "response = runtime_client.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                   ContentType='text/x-libsvm', \n",
    "                                   Body=payload)\n",
    "result = response['Body'].read().decode('ascii')\n",
    "print('Predicted label is {}.'.format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "def do_predict(data, endpoint_name, content_type):\n",
    "    payload = '\\n'.join(data)\n",
    "    response = runtime_client.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                   ContentType=content_type, \n",
    "                                   Body=payload)\n",
    "    result = response['Body'].read().decode('ascii')\n",
    "    preds = [float(num) for num in result.split(',')]\n",
    "    return preds\n",
    "\n",
    "def batch_predict(data, batch_size, endpoint_name, content_type):\n",
    "    items = len(data)\n",
    "    arrs = []\n",
    "    for offset in range(0, items, batch_size):\n",
    "        arrs.extend(do_predict(data[offset:min(offset+batch_size, items)], endpoint_name, content_type))\n",
    "        sys.stdout.write('.')\n",
    "    return(arrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................\n",
      "error rate=0.456654\n",
      "CPU times: user 472 ms, sys: 53.5 ms, total: 526 ms\n",
      "Wall time: 12.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import json\n",
    "\n",
    "file_name = 'wsb.local.test'\n",
    "with open(file_name, 'r') as f:\n",
    "    payload = f.read().strip()\n",
    "\n",
    "labels = [float(line.split(' ')[0]) for line in payload.split('\\n')]\n",
    "test_data = payload.split('\\n')\n",
    "preds = batch_predict(test_data, 100, endpoint_name, 'text/x-libsvm')\n",
    "\n",
    "print ('\\nerror rate=%f' % ( sum(1 for i in range(len(preds)) if preds[i]!=labels[i]) /float(len(preds))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "def error_rate(predictions, labels):\n",
    "    \"\"\"Return the error rate and confusions.\"\"\"\n",
    "    correct = numpy.sum(predictions == labels)\n",
    "    total = predictions.shape[0]\n",
    "\n",
    "    error = 100.0 - (100 * float(correct) / float(total))\n",
    "\n",
    "    confusions = numpy.zeros([10, 10], numpy.int32)\n",
    "    bundled = zip(predictions, labels)\n",
    "    for predicted, actual in bundled:\n",
    "        confusions[int(predicted), int(actual)] += 1\n",
    "    \n",
    "    return error, confusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error: 45.7%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "NUM_LABELS = 3  # change it according to num_class in your dataset\n",
    "test_error, confusions = error_rate(numpy.asarray(preds), numpy.asarray(labels))\n",
    "print('Test error: %.1f%%' % test_error)\n",
    "\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.grid(False)\n",
    "plt.xticks(numpy.arange(NUM_LABELS))\n",
    "plt.yticks(numpy.arange(NUM_LABELS))\n",
    "plt.imshow(confusions, cmap=plt.cm.jet, interpolation='nearest');\n",
    "\n",
    "for i, cas in enumerate(confusions):\n",
    "    for j, count in enumerate(cas):\n",
    "        if count > 0:\n",
    "            xoff = .07 * len(str(count))\n",
    "            plt.text(j-xoff, i+.2, int(count), fontsize=9, color='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'd4b5d553-541d-4d77-ac54-9173c84f2eeb',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'd4b5d553-541d-4d77-ac54-9173c84f2eeb',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Wed, 15 Jul 2020 21:40:41 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
